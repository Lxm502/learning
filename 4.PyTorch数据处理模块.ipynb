{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79186697-5f7a-4256-9554-73463081ffd9",
   "metadata": {},
   "source": [
    "# ğŸ”¹ 4. æ•°æ®å¤„ç†æ¨¡å—\n",
    "\n",
    "### 1ã€torch.utils.data.Datasetï¼šå®šä¹‰è‡ªå®šä¹‰æ•°æ®é›†\n",
    "\n",
    "### 2ã€torch.utils.data.DataLoaderï¼šæ‰¹é‡åŠ è½½æ•°æ®\n",
    "\n",
    "### 3ã€torchvision.datasetsï¼šå¸¸ç”¨æ•°æ®é›†ï¼ˆMNISTã€CIFARã€ImageNet ç­‰ï¼‰\n",
    "\n",
    "### 4ã€torchvision.transformsï¼šå›¾åƒé¢„å¤„ç†ï¼ˆè£å‰ªã€ç¼©æ”¾ã€å½’ä¸€åŒ–ã€å¢å¼ºç­‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d83f6-011f-413a-a25c-e32b8996c911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4edc355c-3fe8-47a0-b58a-ca4620222b81",
   "metadata": {},
   "source": [
    "# 1ã€torch.utils.data.Datasetï¼šå®šä¹‰è‡ªå®šä¹‰æ•°æ®é›†\n",
    "## âš ï¸ æ ¸å¿ƒæ¦‚å¿µï¼šDataset æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "torch.utils.data.Dataset æ˜¯ä¸€ä¸ª æŠ½è±¡ç±» (abstract class)ï¼Œå®ƒä»£è¡¨äº†ä¸€ä¸ªæ•°æ®é›†ã€‚åœ¨ PyTorch ä¸­ï¼Œæ‰€æœ‰è‡ªå®šä¹‰çš„æ•°æ®é›†éƒ½åº”è¯¥ç»§æ‰¿è¿™ä¸ªç±»ã€‚\n",
    "\n",
    "å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ å°†æ•°æ®çš„å…·ä½“å­˜å‚¨ã€è®¿é—®æ–¹å¼ä¸æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹è§£è€¦ã€‚\n",
    "\n",
    "âœ… æ•°æ®é›† (Dataset)ï¼š\\\n",
    "è´Ÿè´£å›ç­”ä¸¤ä¸ªæœ€åŸºæœ¬çš„é—®é¢˜ï¼šâ€œæˆ‘çš„æ•°æ®é›†é‡Œä¸€å…±æœ‰å¤šå°‘ä¸ªæ ·æœ¬ï¼Ÿâ€ (__len__) å’Œ â€œè¯·ç»™æˆ‘ç¬¬ i ä¸ªæ ·æœ¬â€ (__getitem__)ã€‚å®ƒåªå…³å¿ƒå•ä¸ªæ•°æ®æ ·æœ¬çš„è·å–å’Œé¢„å¤„ç†ã€‚\n",
    "\n",
    "âœ… æ•°æ®åŠ è½½å™¨ (DataLoader)ï¼š\\\n",
    "è´Ÿè´£ä» Dataset ä¸­å–å‡ºæ•°æ®ï¼Œå¹¶æŠŠå®ƒä»¬æ‰“åŒ…æˆä¸€ä¸ªä¸ªæ‰¹æ¬¡ (batch)ï¼ŒåŒæ—¶è¿˜å¯ä»¥è¿›è¡Œæ•°æ®æ‰“ä¹± (shuffle) å’Œå¤šè¿›ç¨‹åŠ è½½ç­‰æ“ä½œï¼Œé«˜æ•ˆåœ°å–‚ç»™æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚\n",
    "\n",
    "ç®€å•æ¥è¯´ï¼ŒDataset å®šä¹‰äº†æ•°æ®çš„æ¥æºå’Œå•ä¸€æ ·æœ¬çš„å¤„ç†æ–¹å¼ï¼Œè€Œ DataLoader åˆ™åœ¨æ­¤åŸºç¡€ä¸Šæ„å»ºäº†é«˜æ•ˆçš„æ•°æ®æµã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‘‰ å¦‚ä½•ä½¿ç”¨ Datasetï¼šä¸‰å¤§è¦ç´ \n",
    "è¦åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„ Datasetï¼Œä½ åªéœ€è¦ç»§æ‰¿ torch.utils.data.Dataset å¹¶é‡å†™ (override) ä»¥ä¸‹ä¸‰ä¸ªæ–¹æ³•ï¼š\n",
    "\n",
    "### ğŸ§­ _ _init_ _(self, ...): æ„é€ å‡½æ•°ã€‚\n",
    "\n",
    "ä½œç”¨ï¼šæ‰§è¡Œæ•°æ®é›†çš„åˆå§‹åŒ–æ“ä½œã€‚è¿™é€šå¸¸åŒ…æ‹¬åŠ è½½æ•°æ®ç´¢å¼•ï¼ˆæ¯”å¦‚å›¾ç‰‡è·¯å¾„å’Œå¯¹åº”çš„æ ‡ç­¾ï¼‰ã€å®šä¹‰æ•°æ®å˜æ¢ (transform) ç­‰ã€‚\n",
    "\n",
    "å»ºè®®ï¼šåœ¨è¿™ä¸ªé˜¶æ®µï¼Œä¸è¦ åŠ è½½æ‰€æœ‰çš„æ•°æ®åˆ°å†…å­˜ä¸­ï¼ˆé™¤éä½ çš„æ•°æ®é›†éå¸¸å°ï¼‰ã€‚é€šå¸¸åªåŠ è½½å…ƒä¿¡æ¯ï¼ˆmetadataï¼‰ï¼Œæ¯”å¦‚æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œè¿™æ ·å¯ä»¥èŠ‚çœå¤§é‡å†…å­˜ã€‚\n",
    "\n",
    "### ğŸ§­ _ _len_ _(self): è¿”å›æ•°æ®é›†çš„æ ·æœ¬æ€»æ•°ã€‚\n",
    "\n",
    "ä½œç”¨ï¼šDataLoader éœ€è¦çŸ¥é“æ•°æ®é›†çš„æ€»å¤§å°ï¼Œä»¥ä¾¿ç¡®å®šè¿­ä»£çš„æ¬¡æ•°ã€å¦‚ä½•è¿›è¡Œç´¢å¼•ä»¥åŠå¦‚ä½•ç”Ÿæˆæ‰¹æ¬¡ã€‚\n",
    "\n",
    "å®ç°ï¼šé€šå¸¸æ˜¯è¿”å›ä½ åœ¨ __init__ ä¸­åŠ è½½çš„ç´¢å¼•åˆ—è¡¨çš„é•¿åº¦ã€‚\n",
    "\n",
    "### ğŸ§­ _ _getitem_ _(self, index): æ ¹æ®ç´¢å¼• index è·å–å¹¶è¿”å›ä¸€ä¸ªæ•°æ®æ ·æœ¬ã€‚\n",
    " \n",
    "ä½œç”¨ï¼šè¿™æ˜¯ Dataset çš„æ ¸å¿ƒã€‚DataLoader ä¼šæ ¹æ®éœ€è¦ï¼Œä¼ å…¥ä¸€ä¸ªç´¢å¼• indexï¼Œè¿™ä¸ªæ–¹æ³•åˆ™éœ€è¦æ ¹æ®è¿™ä¸ªç´¢å¼•å®šä½åˆ°å…·ä½“çš„æ•°æ®æ–‡ä»¶ï¼Œè¯»å–å®ƒï¼Œè¿›è¡Œå¿…è¦çš„é¢„å¤„ç†ï¼ˆå¦‚å›¾åƒç¼©æ”¾ã€è£å‰ªã€å½’ä¸€åŒ–ã€è½¬æ¢æˆ Tensor ç­‰ï¼‰ï¼Œæœ€åè¿”å›å¤„ç†å¥½çš„æ•°æ®æ ·æœ¬ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œä¾‹å¦‚ (data_tensor, label_tensor)ï¼‰ã€‚\n",
    "\n",
    "å…³é”®ï¼šçœŸæ­£çš„æ•°æ®åŠ è½½å’Œè½¬æ¢ï¼ˆI/O æ“ä½œå’Œè®¡ç®—ï¼‰å‘ç”Ÿåœ¨è¿™é‡Œï¼Œå®ç°äº†â€œæŒ‰éœ€åŠ è½½â€ï¼Œéå¸¸é«˜æ•ˆã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ä»£ç ç¤ºä¾‹ï¼šè‡ªå®šä¹‰ä¸€ä¸ªå›¾åƒæ•°æ®é›†\n",
    "å‡è®¾æˆ‘ä»¬æœ‰å¦‚ä¸‹çš„æ–‡ä»¶å¤¹ç»“æ„ï¼Œç”¨äºä¸€ä¸ªç®€å•çš„çŒ«ç‹—åˆ†ç±»ä»»åŠ¡ï¼š\n",
    "\n",
    "```\n",
    "data/\n",
    "â”œâ”€â”€ cats/\n",
    "â”‚   â”œâ”€â”€ cat.0.jpg\n",
    "â”‚   â”œâ”€â”€ cat.1.jpg\n",
    "â”‚   â””â”€â”€ ...\n",
    "â””â”€â”€ dogs/\n",
    "    â”œâ”€â”€ dog.0.jpg\n",
    "    â”œâ”€â”€ dog.1.jpg\n",
    "    â””â”€â”€ ...\n",
    "```\n",
    "### ç°åœ¨ï¼Œæˆ‘ä»¬æ¥åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„ Dataset æ¥åŠ è½½è¿™äº›æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1cb10-59d0-40f0-b594-b8a3522d7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image # ç”¨äºè¯»å–å›¾ç‰‡\n",
    "\n",
    "class CatsAndDogsDataset(Dataset):\n",
    "    \"\"\"è‡ªå®šä¹‰çŒ«ç‹—åˆ†ç±»æ•°æ®é›†\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): åŒ…å« 'cats' å’Œ 'dogs' æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•ã€‚\n",
    "            transform (callable, optional): åº”ç”¨äºæ ·æœ¬çš„å¯é€‰å˜æ¢ã€‚\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []  # ç”¨äºå­˜å‚¨ (å›¾ç‰‡è·¯å¾„, æ ‡ç­¾) çš„åˆ—è¡¨\n",
    "\n",
    "        # ä¸ºçŒ«å’Œç‹—åˆ†é…æ ‡ç­¾\n",
    "        # cats -> 0, dogs -> 1\n",
    "        for label, class_name in enumerate(['cats', 'dogs']):\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, file_name)\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        è¿”å›æ•°æ®é›†ä¸­æ ·æœ¬çš„æ€»æ•°ã€‚\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        æ ¹æ®ç´¢å¼• index è·å–ä¸€ä¸ªæ ·æœ¬ã€‚\n",
    "        \"\"\"\n",
    "        # 1. ä» self.samples ä¸­è·å–å›¾ç‰‡è·¯å¾„å’Œæ ‡ç­¾\n",
    "        img_path, label = self.samples[index]\n",
    "\n",
    "        # 2. è¯»å–å›¾ç‰‡\n",
    "        # ä½¿ç”¨ 'L' è½¬æ¢ä¸ºç°åº¦å›¾ï¼Œ'RGB' è½¬æ¢ä¸ºå½©è‰²å›¾\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # 3. å¦‚æœå®šä¹‰äº†å˜æ¢ï¼Œåˆ™å¯¹å›¾ç‰‡è¿›è¡Œå˜æ¢\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # 4. å°†æ ‡ç­¾ä¹Ÿè½¬æ¢ä¸º Tensor (å¯é€‰ï¼Œä½†æ¨è)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        # 5. è¿”å›å¤„ç†å¥½çš„å›¾ç‰‡ Tensor å’Œæ ‡ç­¾ Tensor\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a33d19-a630-449c-b06d-7e74b23fd9e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš ï¸ Dataset ä¸ DataLoader çš„ååŒå·¥ä½œ\n",
    "Dataset æœ¬èº«åªæ˜¯ä¸€ä¸ªæ•°æ®è®¿é—®çš„æ¥å£ï¼Œå®ƒä¸€æ¬¡åªèƒ½é€šè¿‡ [] ç´¢å¼•è¿”å›ä¸€ä¸ªæ ·æœ¬ã€‚è¦å®ç°é«˜æ•ˆçš„è®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦ DataLoaderã€‚\n",
    "\n",
    "DataLoader ä¼šä» Dataset ä¸­è‡ªåŠ¨æ‹‰å–æ•°æ®ï¼Œå¹¶å®Œæˆä»¥ä¸‹å…³é”®å·¥ä½œï¼š\n",
    "\n",
    "- `æ‰¹é‡å¤„ç† (Batching)ï¼šå°†å¤šä¸ªæ ·æœ¬æ‰“åŒ…æˆä¸€ä¸ªæ‰¹æ¬¡ (batch)ã€‚`\n",
    "\n",
    "- `æ•°æ®æ‰“ä¹± (Shuffling)ï¼šåœ¨æ¯ä¸ª epoch å¼€å§‹æ—¶ï¼Œéšæœºæ‰“ä¹±æ•°æ®é¡ºåºï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚`\n",
    "\n",
    "- `å¹¶è¡ŒåŠ è½½ (Parallel Loading)ï¼šä½¿ç”¨å¤šä¸ªå­è¿›ç¨‹ (num_workers) åŒæ­¥åŠ è½½æ•°æ®ï¼Œé¿å…æ•°æ®åŠ è½½æˆä¸º GPU è®¡ç®—çš„ç“¶é¢ˆã€‚`\n",
    "\n",
    "---\n",
    "\n",
    "### ä½¿ç”¨ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4f42c-e5b2-4bae-b098-919e849951ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. å®šä¹‰æ•°æ®å˜æ¢\n",
    "# è¿™é‡Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªç®€å•çš„å˜æ¢ï¼šå°†å›¾ç‰‡ç¼©æ”¾åˆ° 224x224ï¼Œç„¶åè½¬æ¢ä¸º Tensor\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # æ ‡å‡†åŒ–\n",
    "])\n",
    "\n",
    "# 2. å®ä¾‹åŒ–æˆ‘ä»¬è‡ªå®šä¹‰çš„ Dataset\n",
    "dataset_path = 'data/'\n",
    "custom_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=data_transform)\n",
    "print(f\"æ•°æ®é›†å¤§å°: {len(custom_dataset)}\")\n",
    "\n",
    "# 3. å®ä¾‹åŒ– DataLoader\n",
    "# - dataset: æˆ‘ä»¬åˆ›å»ºçš„æ•°æ®é›†å®ä¾‹\n",
    "# - batch_size: æ¯ä¸ªæ‰¹æ¬¡åŒ…å«çš„æ ·æœ¬æ•°\n",
    "# - shuffle: æ˜¯å¦åœ¨æ¯ä¸ª epoch å¼€å§‹æ—¶æ‰“ä¹±æ•°æ®\n",
    "# - num_workers: ç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°é‡\n",
    "data_loader = DataLoader(dataset=custom_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# 4. åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨ DataLoader\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    # DataLoader æ˜¯ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡\n",
    "    for batch_images, batch_labels in data_loader:\n",
    "        # åœ¨è¿™é‡Œï¼Œbatch_images çš„å½¢çŠ¶é€šå¸¸æ˜¯ (batch_size, channels, height, width)\n",
    "        # batch_labels çš„å½¢çŠ¶é€šå¸¸æ˜¯ (batch_size)\n",
    "        \n",
    "        # æ¥ä¸‹æ¥å°±å¯ä»¥å°†è¿™äº›æ‰¹æ¬¡æ•°æ®é€å…¥æ¨¡å‹è¿›è¡Œè®­ç»ƒ\n",
    "        # model(batch_images) ...\n",
    "        \n",
    "        print(f\"  - æ‰¹æ¬¡å›¾åƒå½¢çŠ¶: {batch_images.shape}\")\n",
    "        print(f\"  - æ‰¹æ¬¡æ ‡ç­¾å½¢çŠ¶: {batch_labels.shape}\")\n",
    "        break # è¿™é‡Œåªæ¼”ç¤ºä¸€ä¸ªæ‰¹æ¬¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98a869-e460-4058-945b-c70bbf44db74",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### âš ï¸ ä¸¤ç§ç±»å‹çš„ Dataset\n",
    "PyTorch æä¾›äº†ä¸¤ç§ä¸»è¦ç±»å‹çš„ Datasetï¼š\n",
    "\n",
    "1ã€Map-style Datasets:\n",
    "\n",
    "- `æˆ‘ä»¬ä¸Šé¢å®ç°çš„å°±å±äºè¿™ç§ã€‚`\n",
    "- `å®ƒå®ç°äº† __getitem__() å’Œ __len__() æ–¹æ³•ã€‚`\n",
    "- `å®ƒä»£è¡¨äº†ä»ç´¢å¼• (integer)åˆ°æ•°æ®æ ·æœ¬çš„æ˜ å°„ (map)ã€‚`\n",
    "- `è¿™æ˜¯æœ€å¸¸ç”¨çš„ä¸€ç§ã€‚`\n",
    "\n",
    "2ã€Iterable-style Datasets:\n",
    "\n",
    "- `å®ƒå®ç°äº† __iter__() æ–¹æ³•ã€‚`\n",
    "- `å®ƒä»£è¡¨äº†æ•°æ®æ ·æœ¬çš„ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ (iterable)ï¼Œç±»ä¼¼äº Python çš„ç”Ÿæˆå™¨ã€‚`\n",
    "- `å½“ä½ æ— æ³•äº‹å…ˆçŸ¥é“æ•°æ®é›†çš„æ€»é•¿åº¦ï¼Œæˆ–è€…æ•°æ®æ˜¯ä»æµä¸­è¯»å–æ—¶ï¼ˆä¾‹å¦‚ï¼Œä»æ•°æ®åº“æˆ–è¿œç¨‹æœåŠ¡å™¨æŒç»­è¯»å–ï¼‰ï¼Œè¿™ç§ç±»å‹éå¸¸æœ‰ç”¨ã€‚`\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… æ€»ç»“\n",
    "torch.utils.data.Dataset æ˜¯ PyTorch ä¸­æ„å»ºæ•°æ®è¾“å…¥ç®¡é“çš„åŸºçŸ³ï¼Œå®ƒå®šä¹‰äº†å¦‚ä½•è·å–å•ä¸ªæ•°æ®æ ·æœ¬ã€‚\n",
    "\n",
    "é€šè¿‡ç»§æ‰¿å®ƒå¹¶å®ç° __init__ã€__len__ å’Œ __getitem__ è¿™ä¸‰ä¸ªæ ¸å¿ƒæ–¹æ³•ï¼Œä½ å¯ä»¥ä¸ºä»»ä½•ç±»å‹çš„æ•°æ®åˆ›å»ºè‡ªå®šä¹‰çš„åŠ è½½é€»è¾‘ã€‚\n",
    "\n",
    "Dataset å¿…é¡»ä¸ DataLoader é…åˆä½¿ç”¨ï¼ŒDataLoader åœ¨ Dataset çš„åŸºç¡€ä¸Šæä¾›äº†æ‰¹å¤„ç†ã€æ•°æ®æ‰“ä¹±å’Œå¹¶è¡ŒåŠ è½½ç­‰é«˜çº§åŠŸèƒ½ï¼Œæ˜¯æ„å»ºé«˜æ•ˆã€å¯è¯»æ€§å¼ºçš„æ•°æ®ç®¡é“çš„æ ‡å‡†åšæ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ba47c-20a8-4edb-93ff-71a8b54038a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234af2c0-4ed8-4fa2-bc29-87cc195e6521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49ac7744-e20d-47ef-8d5d-e3be4f79e63b",
   "metadata": {},
   "source": [
    "# 2ã€torch.utils.data.DataLoaderã€‚\n",
    "\n",
    "å¦‚æœè¯´ Dataset æ˜¯ä¸€ä¸ªâ€œæ•°æ®ä»“åº“â€ï¼Œå®šä¹‰äº†æ•°æ®çš„æ€»é‡å’Œè·å–å•ä¸ªæ•°æ®çš„æ–¹æ³•ï¼Œé‚£ä¹ˆ DataLoader å°±æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„â€œæ•°æ®æ¬è¿å·¥â€ï¼Œè´Ÿè´£ä»ä»“åº“ä¸­å–å‡ºæ•°æ®ï¼Œç»è¿‡æ™ºèƒ½æ‰“åŒ…å’Œè¿è¾“ï¼Œé«˜æ•ˆåœ°é€è¾¾â€œæ¨¡å‹â€è¿™ä¸ªå·¥å‚ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ æ ¸å¿ƒæ¦‚å¿µï¼šDataLoader æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "torch.utils.data.DataLoader æ˜¯ä¸€ä¸ª Python å¯è¿­ä»£å¯¹è±¡ (iterable)ã€‚å®ƒå°†ä¸€ä¸ª Dataset å¯¹è±¡åŒ…è£…èµ·æ¥ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§ç®€å•ã€é«˜æ•ˆã€å¯å®šåˆ¶çš„æ–¹å¼æ¥è¿­ä»£è®¿é—®æ•°æ®é›†ã€‚\n",
    "\n",
    "å®ƒè§£å†³äº† Dataset æ— æ³•ç›´æ¥å¤„ç†çš„å‡ ä¸ªå…³é”®é—®é¢˜ï¼Œä½¿å¾—å¤§è§„æ¨¡æ•°æ®è®­ç»ƒæˆä¸ºå¯èƒ½ï¼š\n",
    "\n",
    "- `æ‰¹é‡å¤„ç† (Batching)ï¼š\n",
    "æ¨¡å‹è®­ç»ƒé€šå¸¸é‡‡ç”¨å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ (mini-batch SGD)ï¼Œä¸€æ¬¡å¤„ç†ä¸€å°æ‰¹æ•°æ®è€Œä¸æ˜¯å•ä¸ªæ ·æœ¬ã€‚DataLoader è‡ªåŠ¨å°†ä» Dataset ä¸­å–å‡ºçš„å•ä¸ªæ ·æœ¬æ‰“åŒ…æˆä¸€ä¸ªæ‰¹æ¬¡ (batch)ã€‚`\n",
    "\n",
    "- `æ•°æ®æ‰“ä¹± (Shuffling)ï¼š\n",
    "ä¸ºäº†è®©æ¨¡å‹æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œé¿å…è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬éœ€è¦åœ¨æ¯ä¸ªè®­ç»ƒå‘¨æœŸ (epoch) å¼€å§‹æ—¶æ‰“ä¹±æ•°æ®é¡ºåºã€‚DataLoader å¯ä»¥é€šè¿‡ä¸€ä¸ªç®€å•çš„å‚æ•° shuffle=True å®ç°è¿™ä¸€ç‚¹ã€‚`\n",
    "\n",
    "- `å¹¶è¡ŒåŠ è½½ (Parallel Loading)ï¼š\n",
    "æ•°æ®åŠ è½½ï¼ˆä»ç¡¬ç›˜è¯»å–ã€é¢„å¤„ç†ï¼‰é€šå¸¸æ˜¯ CPU å¯†é›†å‹ä»»åŠ¡ã€‚å¦‚æœä¸²è¡ŒåŠ è½½ï¼ŒGPU å¯èƒ½ä¼šèŠ±è´¹å¤§é‡æ—¶é—´ç­‰å¾… CPU å‡†å¤‡å¥½æ•°æ®ï¼Œé€ æˆâ€œç®—åŠ›é¥¥é¥¿â€ã€‚DataLoader å¯ä»¥ä½¿ç”¨å¤šä¸ªå­è¿›ç¨‹ (num_workers) åœ¨åå°å¹¶è¡ŒåŠ è½½æ•°æ®ï¼Œè®©æ•°æ®å‡†å¤‡å’Œæ¨¡å‹è®¡ç®—åŒæ—¶è¿›è¡Œï¼Œæå¤§åœ°æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚`\n",
    "\n",
    "- `æ•°æ®æ•´åˆ (Collation)ï¼š\n",
    "å°†å¤šä¸ªç‹¬ç«‹çš„æ ·æœ¬ç»„åˆæˆä¸€ä¸ªæ‰¹æ¬¡å¼ é‡ (batch tensor) çš„è¿‡ç¨‹ã€‚DataLoader æœ‰é»˜è®¤çš„æ•´åˆé€»è¾‘ï¼Œä¹Ÿæ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ã€‚`\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ æ ¸å¿ƒå‚æ•°è¯¦è§£\n",
    "DataLoader çš„æ„é€ å‡½æ•°æœ‰å¾ˆå¤šå‚æ•°ï¼Œæˆ‘ä»¬æ¥è®²è§£å…¶ä¸­æœ€é‡è¦ã€æœ€å¸¸ç”¨çš„å‡ ä¸ªï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c45ce-fdcc-4040-87d8-d3301e7834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc71a48-9ef5-4ed8-9b2e-189e2fb1dcdd",
   "metadata": {},
   "source": [
    "## å‚æ•°è¯¦è§£\n",
    "---\n",
    "#### `dataset`ï¼ˆå¿…éœ€ï¼‰\n",
    "- **ç±»å‹**ï¼š`torch.utils.data.Dataset` å¯¹è±¡  \n",
    "- **ä½œç”¨**ï¼šæŒ‡å®šæ•°æ®æ¥æºï¼Œæ˜¯ `DataLoader` çš„æ•°æ®æºã€‚å¿…é¡»ä¼ å…¥ä¸€ä¸ªç»§æ‰¿è‡ª `Dataset` çš„å®ä¾‹ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "#### `batch_size`\n",
    "- **ç±»å‹**ï¼š`int`ï¼Œé»˜è®¤ä¸º `1`  \n",
    "- **ä½œç”¨**ï¼šå®šä¹‰æ¯ä¸ªæ‰¹æ¬¡åŒ…å«çš„æ ·æœ¬æ•°é‡ã€‚  \n",
    "- **å»ºè®®**ï¼šæ ¹æ® GPU æ˜¾å­˜å’Œæ¨¡å‹å¤æ‚åº¦è°ƒæ•´ï¼Œå¸¸è§å€¼ä¸º `16`, `32`, `64`, `128`ã€‚\n",
    "\n",
    "---\n",
    "#### `shuffle`\n",
    "- **ç±»å‹**ï¼š`bool`ï¼Œé»˜è®¤ä¸º `False`  \n",
    "- **ä½œç”¨**ï¼šæ˜¯å¦åœ¨æ¯ä¸ª epoch å¼€å§‹æ—¶æ‰“ä¹±æ•°æ®é¡ºåºã€‚  \n",
    "- **å»ºè®®**ï¼š\n",
    "  - âœ… è®­ç»ƒæ—¶ï¼š`True`ï¼ˆæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼‰\n",
    "  - âŒ éªŒè¯/æµ‹è¯•æ—¶ï¼š`False`ï¼ˆä¿è¯è¯„ä¼°ä¸€è‡´æ€§ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "#### `num_workers`\n",
    "- **ç±»å‹**ï¼š`int`ï¼Œé»˜è®¤ä¸º `0`  \n",
    "- **ä½œç”¨**ï¼šç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°é‡ã€‚\n",
    "  - `0`ï¼šæ‰€æœ‰æ•°æ®åœ¨ä¸»è¿›ç¨‹ä¸­åŠ è½½ï¼ˆåŒæ­¥ï¼‰ã€‚\n",
    "  - `> 0`ï¼šä½¿ç”¨å¤šä¸ªå­è¿›ç¨‹å¼‚æ­¥åŠ è½½æ•°æ®ï¼Œæå‡é€Ÿåº¦ã€‚\n",
    "- **å»ºè®®**ï¼š\n",
    "  - ä¸€èˆ¬è®¾ä¸º `4`, `8`, `16`ï¼Œå»ºè®®ä¸è¶…è¿‡ CPU æ ¸å¿ƒæ•°ã€‚\n",
    "  - Windows ä¸Šæ³¨æ„é¿å… `num_workers > 0` å¯¼è‡´çš„ `freeze_support` é—®é¢˜ï¼ˆå»ºè®®åœ¨ `if __name__ == '__main__':` ä¸­è¿è¡Œï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "#### `pin_memory`\n",
    "- **ç±»å‹**ï¼š`bool`ï¼Œé»˜è®¤ä¸º `False`  \n",
    "- **ä½œç”¨**ï¼šè‹¥ä¸º `True`ï¼Œå°†æ•°æ®åŠ è½½åˆ°â€œå›ºå®šå†…å­˜â€ï¼ˆpinned memoryï¼‰ï¼ŒåŠ å¿«ä» CPU åˆ° GPU çš„ä¼ è¾“é€Ÿåº¦ã€‚  \n",
    "- **å»ºè®®**ï¼š\n",
    "  - âœ… ä½¿ç”¨ GPU è®­ç»ƒæ—¶ï¼šå¼ºçƒˆå»ºè®®è®¾ä¸º `True`\n",
    "  - âŒ CPU è®­ç»ƒæ—¶ï¼šæ— éœ€å¼€å¯\n",
    "\n",
    "---\n",
    "\n",
    "#### `drop_last`\n",
    "- **ç±»å‹**ï¼š`bool`ï¼Œé»˜è®¤ä¸º `False`  \n",
    "- **ä½œç”¨**ï¼šå½“æ ·æœ¬æ€»æ•°ä¸èƒ½è¢« `batch_size` æ•´é™¤æ—¶ï¼Œæœ€åä¸€ä¸ªæ‰¹æ¬¡æ ·æœ¬æ•°ä¼šä¸è¶³ã€‚è‹¥è®¾ä¸º `True`ï¼Œåˆ™ä¸¢å¼ƒè¿™ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡ã€‚  \n",
    "- **åº”ç”¨åœºæ™¯**ï¼š\n",
    "  - æŸäº›æ¨¡å‹è¦æ±‚è¾“å…¥å°ºå¯¸å›ºå®šï¼ˆå¦‚éƒ¨åˆ† RNNã€GANï¼‰\n",
    "  - æ‰¹å½’ä¸€åŒ–ï¼ˆBatchNormï¼‰åœ¨å°æ‰¹æ¬¡ä¸Šä¸ç¨³å®šæ—¶\n",
    "\n",
    "---\n",
    "\n",
    "#### `collate_fn`\n",
    "- **ç±»å‹**ï¼šå¯è°ƒç”¨å‡½æ•°ï¼ˆ`callable`ï¼‰ï¼Œé»˜è®¤ä¸º `None`  \n",
    "- **ä½œç”¨**ï¼šè‡ªå®šä¹‰å¦‚ä½•å°†å¤šä¸ªæ ·æœ¬ç»„åˆæˆä¸€ä¸ªæ‰¹æ¬¡ã€‚é»˜è®¤å‡½æ•°ä¼šå°†å¼ é‡å †å ï¼ˆ`torch.stack`ï¼‰ã€‚  \n",
    "- **é»˜è®¤è¡Œä¸º**ï¼š\n",
    "  ```python\n",
    "  # é»˜è®¤ collate_fn ä¼šåšç±»ä¼¼æ“ä½œ\n",
    "  batch = {\n",
    "      'images': torch.stack([s['image'] for s in samples]),\n",
    "      'labels': torch.tensor([s['label'] for s in samples])\n",
    "  }\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… ä½¿ç”¨å»ºè®®æ€»ç»“\n",
    "\n",
    "| å‚æ•° | è®­ç»ƒæ¨¡å¼å»ºè®® | éªŒè¯/æµ‹è¯•å»ºè®® |\n",
    "|------|---------------|----------------|\n",
    "| `shuffle` | `True` | `False` |\n",
    "| `num_workers` | `4~16`ï¼ˆæ ¹æ® CPUï¼‰ | `4~8` |\n",
    "| `pin_memory` | `True`ï¼ˆGPUï¼‰ | `True`ï¼ˆGPUï¼‰ |\n",
    "| `drop_last` | `True`ï¼ˆè‹¥æ¨¡å‹æ•æ„Ÿï¼‰ | `False` |\n",
    "| `collate_fn` | æŒ‰éœ€è‡ªå®šä¹‰ | æŒ‰éœ€è‡ªå®šä¹‰ |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f537648-afac-4e13-baae-b2c2a1096201",
   "metadata": {},
   "source": [
    "## ğŸ”„ DataLoader å·¥ä½œæµç¨‹è¯¦è§£\n",
    "å½“ä½ å¼€å§‹åœ¨ä¸€ä¸ª DataLoader ä¸Šè¿›è¡Œè¿­ä»£æ—¶ï¼ˆä¾‹å¦‚ï¼šfor batch in data_loader:ï¼‰ï¼Œå…¶å†…éƒ¨ä¼šè‡ªåŠ¨æ‰§è¡Œä¸€ç³»åˆ—é«˜æ•ˆçš„æ“ä½œï¼Œå®ç°æ•°æ®åŠ è½½ä¸æ¨¡å‹è®­ç»ƒçš„æµæ°´çº¿å¹¶è¡Œã€‚æ•´ä¸ªæµç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "### 1ï¸âƒ£ ç”Ÿæˆç´¢å¼•ï¼ˆIndex Generationï¼‰\n",
    "DataLoader é¦–å…ˆé€šè¿‡ä¸€ä¸ª Samplerï¼ˆé‡‡æ ·å™¨ï¼‰ ç”Ÿæˆå½“å‰æ‰¹æ¬¡æ‰€éœ€çš„æ ·æœ¬ç´¢å¼•åˆ—è¡¨ã€‚\\\n",
    "æ ¹æ® shuffle å‚æ•°é€‰æ‹©ä¸åŒçš„é‡‡æ ·ç­–ç•¥ï¼š\n",
    "- `âœ… shuffle=True â†’ ä½¿ç”¨ RandomSamplerï¼ˆéšæœºæ‰“ä¹±é¡ºåºï¼‰`\n",
    "- `âŒ shuffle=False â†’ ä½¿ç”¨ SequentialSamplerï¼ˆæŒ‰é¡ºåºé‡‡æ ·ï¼‰`\n",
    "è¿™äº›ç´¢å¼•å†³å®šäº†æœ¬æ¬¡éœ€è¦åŠ è½½å“ªäº›æ ·æœ¬ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 2ï¸âƒ£ åˆ†å‘ä»»åŠ¡ï¼ˆTask Distributionï¼‰\n",
    "å¦‚æœè®¾ç½®äº† num_workers > 0ï¼ŒDataLoader ä¼šå°†è¿™æ‰¹ç´¢å¼•åˆ†å‘ç»™å¤šä¸ªå­è¿›ç¨‹ï¼ˆworker processesï¼‰ã€‚\\\n",
    "æ¯ä¸ªå­è¿›ç¨‹è´Ÿè´£åŠ è½½ä¸€éƒ¨åˆ†æ•°æ®ï¼Œå®ç°ä»»åŠ¡å¹¶è¡ŒåŒ–ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 3ï¸âƒ£ å¹¶è¡ŒåŠ è½½ï¼ˆParallel Data Loadingï¼‰\n",
    "æ¯ä¸ªå­è¿›ç¨‹ç‹¬ç«‹æ‰§è¡Œï¼š\n",
    "\n",
    "dataset[index]\n",
    "\n",
    "- `å³è°ƒç”¨ Dataset çš„ __getitem__ æ–¹æ³•ã€‚`\n",
    "\n",
    "åŠ è½½è¿‡ç¨‹åŒ…æ‹¬ï¼š`\n",
    "- `æ–‡ä»¶è¯»å–ï¼ˆå¦‚å›¾åƒã€æ–‡æœ¬ï¼‰`\n",
    "- `æ•°æ®è§£ç ï¼ˆå¦‚ PIL åŠ è½½å›¾ç‰‡ï¼‰`\n",
    "- `åº”ç”¨ transform è¿›è¡Œé¢„å¤„ç†`\n",
    "- `æ‰€æœ‰å­è¿›ç¨‹å¹¶è¡Œè¿è¡Œï¼Œæ˜¾è‘—æå‡ I/O æ•ˆç‡ï¼Œé¿å…æˆä¸ºè®­ç»ƒç“¶é¢ˆã€‚`\n",
    "\n",
    "---\n",
    "\n",
    "### 4ï¸âƒ£ æ•´åˆæ•°æ®ï¼ˆCollationï¼‰\n",
    "ä¸»è¿›ç¨‹æ”¶é›†æ‰€æœ‰å­è¿›ç¨‹è¿”å›çš„å•ä¸ªæ ·æœ¬ï¼Œç»„æˆä¸€ä¸ªåˆ—è¡¨ï¼š\n",
    "\n",
    "batch_list = [sample_1, sample_2, ..., sample_batch_size]\n",
    "\n",
    "ç„¶åè°ƒç”¨ collate_fn å‡½æ•°ï¼Œå°†è¯¥åˆ—è¡¨æ•´åˆä¸ºä¸€ä¸ªå®Œæ•´çš„æ‰¹æ¬¡ï¼š\\\n",
    "ğŸ”¹ é»˜è®¤è¡Œä¸ºï¼šä½¿ç”¨ torch.stack() å°†å¼ é‡å †å æˆä¸€ä¸ªå¤§å¼ é‡ã€‚\\\n",
    "ğŸ”¹ è‡ªå®šä¹‰éœ€æ±‚ï¼šå¯¹äºå˜é•¿æ•°æ®ï¼ˆå¦‚ NLP å¥å­ï¼‰ï¼Œéœ€è‡ªå®šä¹‰ collate_fn å®ç° padding æˆ– packingã€‚\\\n",
    "è¾“å‡ºé€šå¸¸ä¸º (inputs, labels) å…ƒç»„æˆ–å­—å…¸å½¢å¼ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 5ï¸âƒ£ è¿”å›æ‰¹æ¬¡ï¼ˆYield Batchï¼‰\n",
    "æ•´åˆåçš„æ‰¹æ¬¡æ•°æ®é€šè¿‡ yield è¿”å›ç»™è®­ç»ƒå¾ªç¯ã€‚\\\n",
    "âš¡ å…³é”®ä¼˜åŠ¿ï¼šåœ¨ä¸»è¿›ç¨‹è¿›è¡Œå‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ç­‰è®¡ç®—çš„åŒæ—¶ï¼Œå­è¿›ç¨‹å·²åœ¨åå°åŠ è½½ä¸‹ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œå½¢æˆâ€œæµæ°´çº¿å¹¶è¡Œï¼ˆPipeliningï¼‰â€ï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdfb60d-7d99-4105-9807-277a8a112fb9",
   "metadata": {},
   "source": [
    "---\n",
    "### ä»£ç ç¤ºä¾‹\n",
    "æˆ‘ä»¬ç»§ç»­ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„ CatsAndDogsDatasetã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69962f0-ca95-491e-8cdb-c33919fdaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# å‡è®¾ CatsAndDogsDataset ç±»å·²ç»åœ¨è¿™é‡Œå®šä¹‰å¥½äº†\n",
    "# class CatsAndDogsDataset(Dataset):\n",
    "#     ...\n",
    "\n",
    "# 1. å®šä¹‰æ•°æ®å˜æ¢\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. å®ä¾‹åŒ– Dataset\n",
    "dataset_path = 'data/'\n",
    "train_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=data_transform)\n",
    "\n",
    "# 3. å®ä¾‹åŒ– DataLoaderï¼Œå¹¶é…ç½®æ ¸å¿ƒå‚æ•°\n",
    "# è¿™æ˜¯è®­ç»ƒé›†åŠ è½½å™¨ï¼Œæ‰€ä»¥ shuffle=True\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,       # æ¯ä¸ªæ‰¹æ¬¡åŠ è½½ 64 å¼ å›¾ç‰‡\n",
    "    shuffle=True,        # æ¯ä¸ª epoch éƒ½æ‰“ä¹±æ•°æ®\n",
    "    num_workers=4,       # ä½¿ç”¨ 4 ä¸ªå­è¿›ç¨‹æ¥åŠ è½½æ•°æ®\n",
    "    pin_memory=True      # å¦‚æœä½¿ç”¨ GPUï¼Œè®¾ç½®ä¸º True\n",
    ")\n",
    "\n",
    "# 4. åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨ DataLoader\n",
    "print(f\"å¼€å§‹éå† train_loader...\")\n",
    "# DataLoader æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œæˆ‘ä»¬å¯ä»¥åƒéå†åˆ—è¡¨ä¸€æ ·éå†å®ƒ\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    # å°†æ•°æ®ç§»åŠ¨åˆ° GPU (å¦‚æœå¯ç”¨)\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # images = images.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    \n",
    "    # æ‰“å°æ‰¹æ¬¡æ•°æ®çš„å½¢çŠ¶\n",
    "    print(f\"æ‰¹æ¬¡ {i+1}:\")\n",
    "    print(f\"  - å›¾åƒæ‰¹æ¬¡çš„å½¢çŠ¶: {images.shape}\")  # torch.Size([64, 3, 224, 224])\n",
    "    print(f\"  - æ ‡ç­¾æ‰¹æ¬¡çš„å½¢çŠ¶: {labels.shape}\")  # torch.Size([64])\n",
    "\n",
    "    # åœ¨è¿™é‡Œï¼Œå¯ä»¥å°† images å’Œ labels é€å…¥æ¨¡å‹è¿›è¡Œè®­ç»ƒ\n",
    "    # e.g., outputs = model(images)\n",
    "    #        loss = criterion(outputs, labels)\n",
    "    #        ...\n",
    "\n",
    "    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åªéå†å‡ ä¸ªæ‰¹æ¬¡å°±é€€å‡º\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889b521-a466-4d59-b3bf-de7d2fc4d712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e935ab7-6a15-4d03-9ee5-32a44dece253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc8e808-35fc-4675-9e0c-ce02bdbc2fd6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ece21-ddb4-4011-bc4d-df780290fc9e",
   "metadata": {},
   "source": [
    "# 4ã€torchvision.transformsã€‚\n",
    "åœ¨ Dataset è´Ÿè´£å®šä½å’Œè¯»å–åŸå§‹æ•°æ®ã€DataLoader è´Ÿè´£æ‰“åŒ…å’ŒåŠ è½½æ•°æ®ä¹‹åï¼Œtransforms åˆ™è´Ÿè´£åœ¨æ•°æ®é€å…¥æ¨¡å‹å‰ï¼Œå¯¹åŸå§‹æ•°æ®ï¼ˆé€šå¸¸æ˜¯ PIL Image å¯¹è±¡ï¼‰è¿›è¡Œä¸€ç³»åˆ—çš„â€œåŠ å·¥å¤„ç†â€ã€‚\n",
    "\n",
    "## âš¡ æ ¸å¿ƒæ¦‚å¿µï¼štransforms æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "torchvision.transforms æ¨¡å—åŒ…å«äº†ä¸€ç³»åˆ—å¸¸è§çš„å›¾åƒå˜æ¢æ“ä½œã€‚è¿™äº›æ“ä½œå¯ä»¥è¢«ä¸²è”èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå¤„ç†æµæ°´çº¿ã€‚å®ƒçš„æ ¸å¿ƒä½œç”¨ä¸»è¦æœ‰ä¸¤ä¸ªï¼š\n",
    "\n",
    "### 1ã€æ•°æ®é¢„å¤„ç† (Data Preprocessing)ï¼š\n",
    "\n",
    "- `ç¥ç»ç½‘ç»œè¦æ±‚è¾“å…¥çš„æ•°æ®å…·æœ‰å›ºå®šçš„å°ºå¯¸ã€æ ¼å¼å’Œæ•°æ®èŒƒå›´ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹å¯èƒ½è¦æ±‚æ‰€æœ‰è¾“å…¥å›¾ç‰‡éƒ½æ˜¯ 224x224 åƒç´ ï¼Œå¹¶ä¸”æ˜¯ torch.Tensor ç±»å‹ï¼Œåƒç´ å€¼ä¹Ÿéœ€è¦ç»è¿‡å½’ä¸€åŒ–ã€‚transforms å°±æ˜¯ç”¨æ¥å®Œæˆè¿™äº›æ ‡å‡†åŒ–å·¥ä½œçš„ã€‚`\n",
    "\n",
    "- âš ï¸`å…³é”®æ­¥éª¤ï¼šå°ºå¯¸è°ƒæ•´ã€è½¬æ¢æˆå¼ é‡ (Tensor)ã€æ•°æ®å½’ä¸€åŒ–ã€‚`\n",
    "\n",
    "### 2ã€æ•°æ®å¢å¼º (Data Augmentation)ï¼š\n",
    "\n",
    "- `è¿™æ˜¯æå‡æ¨¡å‹æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›çš„å…³é”®æŠ€æœ¯ã€‚é€šè¿‡å¯¹è®­ç»ƒå›¾åƒè¿›è¡Œä¸€ç³»åˆ—éšæœºçš„å˜æ¢ï¼ˆå¦‚éšæœºç¿»è½¬ã€æ—‹è½¬ã€è£å‰ªã€è‰²å½©æŠ–åŠ¨ç­‰ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å‡­ç©ºåˆ›é€ å‡ºæ›´å¤šæ ·åŒ–çš„è®­ç»ƒæ ·æœ¬ã€‚`\n",
    "\n",
    "- `è¿™ç›¸å½“äºæ‰©å……äº†è®­ç»ƒé›†ï¼Œè®©æ¨¡å‹åœ¨è®­ç»ƒæ—¶çœ‹åˆ°â€œåƒå˜ä¸‡åŒ–â€çš„å›¾åƒï¼Œä»è€Œå­¦ä¹ åˆ°æ›´æœ¬è´¨ã€æ›´é²æ£’çš„ç‰¹å¾ï¼Œæœ‰æ•ˆé˜²æ­¢è¿‡æ‹Ÿåˆã€‚`\n",
    "\n",
    "- `é‡è¦åŸåˆ™ï¼šæ•°æ®å¢å¼ºåªåº”åœ¨è®­ç»ƒé›† (training set) ä¸Šä½¿ç”¨ã€‚åœ¨éªŒè¯é›† (validation set) å’Œæµ‹è¯•é›† (test set) ä¸Šï¼Œæˆ‘ä»¬åªéœ€è¦è¿›è¡Œå¿…è¦çš„é¢„å¤„ç†ï¼Œä»¥ç¡®ä¿è¯„ä¼°ç»“æœçš„ä¸€è‡´æ€§å’Œå¯å¤ç°æ€§ã€‚`\n",
    "\n",
    "---\n",
    "\n",
    "## å¦‚ä½•ä½¿ç”¨ï¼štransforms.Compose\n",
    "transforms æ¨¡å—ä¸­æœ€å¸¸ç”¨çš„ä¸€ä¸ªç±»æ˜¯ transforms.Composeã€‚å®ƒçš„ä½œç”¨å°±åƒä¸€ä¸ªå®¹å™¨ï¼Œå¯ä»¥å°†å¤šä¸ªå˜æ¢æ“ä½œä¸²è”æˆä¸€ä¸ªåºåˆ—ã€‚å½“ä½ è°ƒç”¨è¿™ä¸ª Compose å¯¹è±¡æ—¶ï¼Œå®ƒä¼šæŒ‰ç…§ä½ å®šä¹‰çš„é¡ºåºï¼Œä¾æ¬¡å¯¹è¾“å…¥çš„å›¾åƒæ‰§è¡Œæ¯ä¸€ä¸ªå˜æ¢ã€‚\n",
    "\n",
    "### åŸºæœ¬ç”¨æ³•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150e2e7-ef21-440e-a627-006be7b73532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå˜æ¢åºåˆ—\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),             # 1. å…ˆæŠŠå›¾ç‰‡å°ºå¯¸ç¼©æ”¾åˆ° 256x256\n",
    "    transforms.CenterCrop(224),         # 2. ç„¶åä»ä¸­å¿ƒè£å‰ªå‡º 224x224 çš„åŒºåŸŸ\n",
    "    transforms.ToTensor(),              # 3. è½¬æ¢ä¸º Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 4. è¿›è¡Œå½’ä¸€åŒ–\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ä½¿ç”¨\n",
    "# from PIL import Image\n",
    "# image = Image.open(\"path/to/your/image.jpg\")\n",
    "# transformed_image = data_transform(image) # åº”ç”¨å˜æ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22951d9e-153e-4408-8dd5-84f6de89babd",
   "metadata": {},
   "source": [
    "## å¸¸ç”¨ transforms åˆ†ç±»è¯¦è§£\n",
    "ä¸‹é¢æˆ‘ä»¬åˆ†ç±»ä»‹ç»ä¸€äº›æœ€å¸¸ç”¨çš„å˜æ¢åŠŸèƒ½ã€‚\n",
    "\n",
    "1. å°ºå¯¸ä¸è£å‰ª (Sizing and Cropping)\n",
    "- `transforms.Resize(size): å°†è¾“å…¥å›¾åƒçš„å°ºå¯¸è°ƒæ•´ä¸ºæŒ‡å®šå¤§å°ã€‚size å¯ä»¥æ˜¯ä¸€ä¸ªæ•´æ•°ï¼ˆçŸ­è¾¹ç¼©æ”¾åˆ°è¯¥å°ºå¯¸ï¼Œé•¿è¾¹ç­‰æ¯”ç¼©æ”¾ï¼‰æˆ–ä¸€ä¸ªå…ƒç»„ (h, w)ã€‚`\n",
    "\n",
    "- `transforms.CenterCrop(size): ä»å›¾åƒä¸­å¿ƒè£å‰ªå‡ºæŒ‡å®šå¤§å°çš„åŒºåŸŸã€‚`\n",
    "\n",
    "- `transforms.RandomCrop(size, padding=None): ä»ä¸€ä¸ªéšæœºä½ç½®è£å‰ªå‡ºæŒ‡å®šå¤§å°çš„åŒºåŸŸã€‚å¸¸ç”¨äºæ•°æ®å¢å¼ºã€‚`\n",
    "\n",
    "- `transforms.RandomResizedCrop(size, scale=(0.08, 1.0)): è¿™æ˜¯è®­ç»ƒæ—¶éå¸¸å¸¸ç”¨ä¸”å¼ºå¤§çš„ä¸€ä¸ªå˜æ¢ã€‚å®ƒä¼šéšæœºè£å‰ªåŸå§‹å›¾åƒçš„ä¸€ä¸ªåŒºåŸŸï¼ˆè£å‰ªé¢ç§¯å’Œé•¿å®½æ¯”éƒ½æ˜¯éšæœºçš„ï¼‰ï¼Œç„¶åå°†è¿™ä¸ªåŒºåŸŸç¼©æ”¾åˆ°æŒ‡å®šå¤§å°ã€‚è¿™æ¨¡æ‹Ÿäº†ç‰©ä½“åœ¨ä¸åŒå°ºåº¦å’Œä½ç½®å‡ºç°çš„æƒ…å†µã€‚`\n",
    "\n",
    "2. ç¿»è½¬ä¸æ—‹è½¬ (Flipping and Rotation)\n",
    "- `transforms.RandomHorizontalFlip(p=0.5): ä»¥ p çš„æ¦‚ç‡ï¼ˆé»˜è®¤ä¸º 0.5ï¼‰å¯¹å›¾åƒè¿›è¡Œæ°´å¹³ç¿»è½¬ã€‚`\n",
    "\n",
    "- `transforms.RandomVerticalFlip(p=0.5): ä»¥ p çš„æ¦‚ç‡å¯¹å›¾åƒè¿›è¡Œå‚ç›´ç¿»è½¬ã€‚`\n",
    "\n",
    "- `transforms.RandomRotation(degrees): åœ¨ (-degrees, +degrees) èŒƒå›´å†…éšæœºæ—‹è½¬å›¾åƒã€‚`\n",
    "\n",
    "3. ç±»å‹è½¬æ¢ä¸å½’ä¸€åŒ– (Crucial Steps)\n",
    "- `transforms.ToTensor(): è¿™æ˜¯è‡³å…³é‡è¦çš„ä¸€æ­¥ï¼Œå®ƒåšäº†ä¸‰ä»¶äº‹ï¼š`\n",
    "\n",
    "- 1ã€ `å°†è¾“å…¥çš„ PIL Image æˆ– numpy.ndarray è½¬æ¢æˆ torch.Tensorã€‚`\n",
    "\n",
    "- 2ã€ `å°†åƒç´ å€¼ä» [0, 255] çš„èŒƒå›´ç¼©æ”¾åˆ° [0.0, 1.0] çš„èŒƒå›´ã€‚`\n",
    "\n",
    "- 3ã€ `å°†å›¾åƒçš„ç»´åº¦é¡ºåºä» (H, W, C) (é«˜, å®½, é€šé“) æ”¹å˜ä¸º (C, H, W) (é€šé“, é«˜, å®½)ï¼Œè¿™æ˜¯ PyTorch æ¨¡å‹æœŸæœ›çš„è¾“å…¥æ ¼å¼ã€‚`\n",
    "\n",
    "- `transforms.Normalize(mean, std): ç”¨ç»™å®šçš„å‡å€¼ (mean) å’Œæ ‡å‡†å·® (std) å¯¹å¼ é‡å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚`\n",
    "\n",
    "å…¬å¼ï¼šoutput=(inputâˆ’mean)/std\n",
    "\n",
    "- `ä½œç”¨ï¼šä½¿ä¸åŒé€šé“çš„åƒç´ å€¼åˆ†å¸ƒåœ¨ç›¸ä¼¼çš„èŒƒå›´å†…ï¼Œè¿™æœ‰åŠ©äºåŠ é€Ÿæ¨¡å‹æ”¶æ•›ã€‚`\n",
    "\n",
    "- `mean å’Œ std éƒ½æ˜¯ä¸€ä¸ªåŒ…å« C ä¸ªå…ƒç´ ï¼ˆå¯¹åº” C ä¸ªé€šé“ï¼‰çš„åºåˆ—ã€‚å¯¹äºåœ¨ ImageNet æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œé€šå¸¸ä½¿ç”¨ä»¥ä¸‹å€¼ï¼š`\n",
    "\n",
    "- `mean=[0.485, 0.456, 0.406]`\n",
    "\n",
    "- `std=[0.229, 0.224, 0.225]`\n",
    "\n",
    "4. è‰²å½©ä¸äº®åº¦ (Color Augmentation)\n",
    "- `transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0): éšæœºæ”¹å˜å›¾åƒçš„äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦å’Œè‰²è°ƒã€‚è¿™æ˜¯éå¸¸æœ‰æ•ˆçš„é¢œè‰²æ•°æ®å¢å¼ºæ–¹æ³•ã€‚`\n",
    "\n",
    "- `transforms.Grayscale(num_output_channels=1): å°†å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾ã€‚`\n",
    "\n",
    "---\n",
    "\n",
    "## å®æˆ˜ï¼šä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†æ„å»ºä¸åŒçš„å¤„ç†æµ\n",
    "è¿™æ˜¯ä¸€ä¸ªæœ€ä½³å®è·µï¼Œå±•ç¤ºäº†å¦‚ä½•ä¸ºè®­ç»ƒå’ŒéªŒè¯/æµ‹è¯•é˜¶æ®µå®šä¹‰ä¸åŒçš„ transforms ç®¡é“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd2ea3-20b6-40cf-a64f-23227673cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# å‡è®¾æˆ‘ä»¬æœ‰ä¹‹å‰å®šä¹‰çš„ CatsAndDogsDataset\n",
    "\n",
    "# 1. ä¸ºè®­ç»ƒé›†å®šä¹‰å˜æ¢ï¼šåŒ…å«æ•°æ®å¢å¼º\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # éšæœºè£å‰ªå’Œç¼©æ”¾\n",
    "    transforms.RandomHorizontalFlip(),    # éšæœºæ°´å¹³ç¿»è½¬\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # éšæœºé¢œè‰²æŠ–åŠ¨\n",
    "    transforms.ToTensor(),                # è½¬æ¢ä¸º Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # å½’ä¸€åŒ–\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. ä¸ºéªŒè¯é›†/æµ‹è¯•é›†å®šä¹‰å˜æ¢ï¼šåªåšå¿…è¦çš„é¢„å¤„ç†\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),             # ç¼©æ”¾\n",
    "    transforms.CenterCrop(224),         # ä¸­å¿ƒè£å‰ª\n",
    "    transforms.ToTensor(),                # è½¬æ¢ä¸º Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # å½’ä¸€åŒ–\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# 3. åœ¨åˆ›å»º Dataset å®ä¾‹æ—¶ä¼ å…¥å¯¹åº”çš„ transforms\n",
    "dataset_path = 'data/'\n",
    "\n",
    "# è®­ç»ƒé›†ä½¿ç”¨å¸¦æ•°æ®å¢å¼ºçš„å˜æ¢\n",
    "train_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=train_transforms)\n",
    "\n",
    "# éªŒè¯é›†ä½¿ç”¨å›ºå®šçš„é¢„å¤„ç†å˜æ¢\n",
    "val_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=val_test_transforms)\n",
    "\n",
    "\n",
    "# 4. åˆ›å»º DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4) # éªŒè¯é›†ä¸éœ€è¦ shuffle\n",
    "\n",
    "# ç°åœ¨ï¼Œä» train_loader ä¸­å–å‡ºçš„æ¯ä¸ªæ‰¹æ¬¡éƒ½æ˜¯ç»è¿‡éšæœºå¢å¼ºçš„ï¼Œè€Œ val_loader ä¸­çš„æ•°æ®åˆ™æ˜¯ç¡®å®šæ€§çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e70f2b-658c-4d07-8f75-32ca809098a8",
   "metadata": {},
   "source": [
    "---\n",
    "# æ€»ç»“\n",
    "torchvision.transforms æ˜¯æ„å»ºè®¡ç®—æœºè§†è§‰æ•°æ®ç®¡é“çš„æ ¸å¿ƒç»„ä»¶ã€‚\n",
    "\n",
    "å®ƒçš„ä¸¤å¤§èŒè´£æ˜¯æ•°æ®é¢„å¤„ç†ï¼ˆä½¿æ•°æ®ç¬¦åˆæ¨¡å‹è¾“å…¥è¦æ±‚ï¼‰å’Œæ•°æ®å¢å¼ºï¼ˆæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼‰ã€‚\n",
    "\n",
    "ä½¿ç”¨ transforms.Compose å¯ä»¥æ–¹ä¾¿åœ°å°†å¤šä¸ªæ“ä½œé“¾æ¥æˆä¸€ä¸ªå¤„ç†æµæ°´çº¿ã€‚\n",
    "\n",
    "ToTensor() å’Œ Normalize() æ˜¯å‡ ä¹æ‰€æœ‰å›¾åƒé¢„å¤„ç†æµç¨‹ä¸­éƒ½å¿…ä¸å¯å°‘çš„æ­¥éª¤ã€‚\n",
    "\n",
    "#### âš ï¸åŠ¡å¿…è®°ä½ï¼š\n",
    "ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯/æµ‹è¯•é›†è®¾ç½®ä¸åŒçš„å˜æ¢æµç¨‹ï¼Œæ•°æ®å¢å¼ºåªç”¨äºè®­ç»ƒé›†ã€‚è¿™å¥— Dataset + DataLoader + transforms \n",
    "çš„ç»„åˆæ‹³æ˜¯æ‰€æœ‰ PyTorch è§†è§‰ä»»åŠ¡çš„æ ‡å‡†èµ·ç‚¹ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8728b4-e438-43df-8588-62b8a443c23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0b36041-17dd-4390-8efa-056265fe4282",
   "metadata": {},
   "source": [
    "# torchvision.transforms.ToTensor()\n",
    "å ªç§°æ˜¯â€œå®ˆé—¨å‘˜â€å’Œâ€œæ ¼å¼è½¬æ¢å®˜â€ï¼Œæ˜¯è¿æ¥å›¾åƒä¸–ç•Œï¼ˆPIL, NumPyï¼‰å’Œ PyTorch å¼ é‡ä¸–ç•Œï¼ˆTensorï¼‰æœ€å…³é”®çš„æ¡¥æ¢ã€‚ç†è§£å®ƒçš„å…·ä½“å·¥ä½œæ–¹å¼è‡³å…³é‡è¦ã€‚\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚è¿°\n",
    "transforms.ToTensor() çš„ä¸»è¦åŠŸèƒ½æ˜¯å°†ä¸€ä¸ª PIL Image å¯¹è±¡æˆ–ä¸€ä¸ª numpy.ndarray å¯¹è±¡è½¬æ¢ä¸º torch.Tensorã€‚\n",
    "\n",
    "ç„¶è€Œï¼Œè¿™ä¸ªè½¬æ¢è¿‡ç¨‹å¹¶éç®€å•çš„ç±»å‹å¼ºåˆ¶è½¬æ¢ï¼Œå®ƒç²¾ç¡®åœ°æ‰§è¡Œäº†ä¸‰ä¸ªæ ¸å¿ƒæ“ä½œã€‚\n",
    "\n",
    "---\n",
    "## ToTensor() çš„ä¸‰å¤§æ ¸å¿ƒæ“ä½œ\n",
    "### 1. è½¬æ¢æ•°æ®ç±»å‹ (Convert Data Type)\n",
    "- `å®ƒä¼šå°†è¾“å…¥çš„ PIL å›¾åƒæˆ– NumPy æ•°ç»„è½¬æ¢ä¸º torch.FloatTensorã€‚è¿™æ„å‘³ç€è¾“å‡ºçš„å¼ é‡å°†æ˜¯32ä½æµ®ç‚¹æ•°ç±»å‹ï¼Œè¿™æ˜¯ç¥ç»ç½‘ç»œè¿›è¡Œè®¡ç®—æ‰€æœŸæœ›çš„æ ‡å‡†ç±»å‹ã€‚`\n",
    "\n",
    "### 2. å½’ä¸€åŒ–åƒç´ å€¼ (Normalize Pixel Values)\n",
    "- `è¿™æ˜¯éå¸¸é‡è¦çš„ä¸€æ­¥ã€‚åŸå§‹å›¾åƒçš„åƒç´ å€¼é€šå¸¸å­˜å‚¨ä¸º uint8 ç±»å‹ï¼ŒèŒƒå›´åœ¨ [0, 255] ä¹‹é—´ã€‚ToTensor() ä¼šå°†è¿™ä¸ªèŒƒå›´ç­‰æ¯”ä¾‹åœ°ç¼©æ”¾åˆ° [0.0, 1.0] ä¹‹é—´ã€‚`\n",
    "\n",
    "å®ç°æ–¹å¼ï¼šå¾ˆç®€å•ï¼Œå°±æ˜¯å°†æ¯ä¸ªåƒç´ å€¼é™¤ä»¥ 255ã€‚\n",
    "\n",
    "- `ä¸ºä»€ä¹ˆè¿™ä¹ˆåšï¼šå°†æ•°æ®ç¼©æ”¾åˆ°ä¸€ä¸ªè¾ƒå°çš„ã€æ ‡å‡†åŒ–çš„èŒƒå›´ï¼ˆå¦‚ [0, 1] æˆ– [-1, 1]ï¼‰æœ‰åŠ©äºç¥ç»ç½‘ç»œçš„ç¨³å®šè®­ç»ƒå’Œå¿«é€Ÿæ”¶æ•›ã€‚[0, 1] æ˜¯æœ€å¸¸è§çš„èµ·ç‚¹ã€‚`\n",
    "\n",
    "### 3. è°ƒæ•´ç»´åº¦é¡ºåº (Adjust Dimension Order)\n",
    "è¿™æ˜¯åˆå­¦è€…æœ€å®¹æ˜“æ··æ·†ã€ä¹Ÿæœ€éœ€è¦æ³¨æ„çš„ä¸€ç‚¹ã€‚\n",
    "\n",
    "- `è¾“å…¥æ ¼å¼ (å›¾åƒä¸–ç•Œ)ï¼šå¯¹äºä¸€ä¸ªæ ‡å‡†çš„å½©è‰²å›¾åƒï¼Œå…¶æ•°æ®é€šå¸¸ä»¥ HWC æ ¼å¼å­˜å‚¨ï¼Œå³ (Height, Width, Channels)ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ª 224x224 çš„ RGB å›¾åƒï¼Œå…¶ NumPy æ•°ç»„çš„å½¢çŠ¶ä¼šæ˜¯ (224, 224, 3)ã€‚`\n",
    "\n",
    "- `è¾“å‡ºæ ¼å¼ (PyTorch ä¸–ç•Œ)ï¼šPyTorch ä¸­çš„å·ç§¯ç¥ç»ç½‘ç»œç­‰æ¨¡å—æœŸæœ›çš„å›¾åƒè¾“å…¥æ ¼å¼æ˜¯ CHWï¼Œå³ (Channels, Height, Width)ã€‚å› æ­¤ï¼ŒToTensor() ä¼šè‡ªåŠ¨é‡æ–°æ’åˆ—ç»´åº¦ã€‚åŒä¸€ä¸ª 224x224 çš„ RGB å›¾åƒï¼Œè½¬æ¢åçš„å¼ é‡å½¢çŠ¶ä¼šæ˜¯ (3, 224, 224)ã€‚`\n",
    "\n",
    "### æ€»ç»“ä¸€ä¸‹ç»´åº¦çš„å˜åŒ–ï¼š\n",
    "| è¾“å…¥ç±»å‹      | è¾“å…¥å½¢çŠ¶   | è¾“å‡ºå½¢çŠ¶  |\n",
    "|---------------|------------|-----------|\n",
    "| numpy.ndarray | H x W x C  | C x H x W |\n",
    "| PIL.Image     | (éšå¼ HWC) | C x H x W |\n",
    "                                  å¯¹äºç°åº¦å›¾ï¼ŒH x W ä¼šå˜ä¸º 1 x H x Wï¼Œå¢åŠ ä¸€ä¸ªé€šé“ç»´åº¦ã€‚\n",
    "\n",
    "---\n",
    "### ä»£ç æ¼”ç¤º\n",
    "è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå…·ä½“çš„ä¾‹å­æ¥çœ‹çœ‹è¿™ä¸‰ä¸ªæ“ä½œæ˜¯å¦‚ä½•å‘ç”Ÿçš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee0f24-84f3-4129-b9b6-e793b2e24f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 1. åˆ›å»ºä¸€ä¸ªç¤ºä¾‹ NumPy æ•°ç»„ (æ¨¡æ‹Ÿä¸€å¼  3x4 çš„ RGB å›¾ç‰‡)\n",
    "# å½¢çŠ¶ä¸º HWC: (3, 4, 3)\n",
    "# æ•°æ®ç±»å‹ä¸º uint8, èŒƒå›´ [0, 255]\n",
    "# æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ£‹ç›˜æ ¼æ¨¡å¼ä»¥ä¾¿è§‚å¯Ÿ\n",
    "numpy_image = np.array([\n",
    "    [[255, 0, 0], [255, 255, 0], [0, 255, 0], [0, 255, 255]],\n",
    "    [[0, 0, 255], [255, 0, 255], [0, 0, 0],   [127, 127, 127]],\n",
    "    [[50, 100, 150], [200, 150, 100], [75, 125, 175], [0, 50, 250]]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "print(f\"åŸå§‹ NumPy æ•°ç»„:\")\n",
    "print(f\"  - ç±»å‹: {numpy_image.dtype}\")\n",
    "print(f\"  - å½¢çŠ¶: {numpy_image.shape}\")\n",
    "print(f\"  - å³ä¸Šè§’åƒç´ å€¼ (R,G,B): {numpy_image[0, 3, :]}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 2. ä» NumPy æ•°ç»„åˆ›å»º PIL Image å¯¹è±¡\n",
    "pil_image = Image.fromarray(numpy_image)\n",
    "print(f\"åŸå§‹ PIL Image å¯¹è±¡:\")\n",
    "print(f\"  - æ¨¡å¼: {pil_image.mode}\")\n",
    "print(f\"  - å°ºå¯¸ (W, H): {pil_image.size}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# 3. å®ä¾‹åŒ–å¹¶åº”ç”¨ ToTensor\n",
    "to_tensor_transform = transforms.ToTensor()\n",
    "tensor_from_numpy = to_tensor_transform(numpy_image)\n",
    "tensor_from_pil = to_tensor_transform(pil_image)\n",
    "\n",
    "# 4. æ£€æŸ¥è½¬æ¢åçš„ Tensor (ä»¥ NumPy è½¬æ¢ç»“æœä¸ºä¾‹)\n",
    "print(f\"è½¬æ¢åçš„ Tensor:\")\n",
    "print(f\"  - ç±»å‹: {tensor_from_numpy.dtype}\")\n",
    "print(f\"  - å½¢çŠ¶: {tensor_from_numpy.shape}\") # æ³¨æ„ï¼å½¢çŠ¶ä» (3, 4, 3) å˜ä¸º (3, 3, 4)\n",
    "print(f\"  - å³ä¸Šè§’åƒç´ å€¼ (R,G,B):\")\n",
    "# è®¿é—®æ–¹å¼å˜ä¸º [channel, height, width]\n",
    "red_channel_val = tensor_from_numpy[0, 0, 3] # çº¢è‰²é€šé“\n",
    "green_channel_val = tensor_from_numpy[1, 0, 3] # ç»¿è‰²é€šé“\n",
    "blue_channel_val = tensor_from_numpy[2, 0, 3] # è“è‰²é€šé“\n",
    "print(f\"    - R: {red_channel_val:.4f} (åŸå§‹å€¼ 0 / 255)\")\n",
    "print(f\"    - G: {green_channel_val:.4f} (åŸå§‹å€¼ 255 / 255)\")\n",
    "print(f\"    - B: {blue_channel_val:.4f} (åŸå§‹å€¼ 255 / 255)\")\n",
    "\n",
    "# éªŒè¯ä¸¤ä¸ªè½¬æ¢ç»“æœæ˜¯å¦ä¸€è‡´\n",
    "assert torch.equal(tensor_from_numpy, tensor_from_pil)\n",
    "print(\"\\nä» NumPy å’Œ PIL è½¬æ¢çš„ Tensor ç»“æœä¸€è‡´ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556f7a7-b143-4975-bc9a-021aa5c4e175",
   "metadata": {},
   "source": [
    "### è¾“å‡ºåˆ†æï¼š\n",
    "\n",
    "- `ç±»å‹å˜åŒ–: uint8 -> torch.float32ã€‚`\n",
    "\n",
    "- `å½¢çŠ¶å˜åŒ–: (3, 4, 3) -> torch.Size([3, 3, 4])ï¼Œå®Œç¾å±•ç¤ºäº† HWC -> CHW çš„ç»´åº¦é‡æ’ã€‚`\n",
    "\n",
    "- `å€¼ç¼©æ”¾: åŸå§‹å€¼ [0, 255, 255] ç»è¿‡é™¤ä»¥ 255 åï¼Œå˜ä¸ºäº† [0.0, 1.0, 1.0]ã€‚`\n",
    "\n",
    "---\n",
    "\n",
    "### åœ¨ transforms.Compose ä¸­çš„ä½ç½®\n",
    "- `ToTensor() åœ¨ Compose ç®¡é“ä¸­é€šå¸¸å¤„äºä¸­é—´ä½ç½®ã€‚`\n",
    "\n",
    "- `å®ƒå¿…é¡»åœ¨æ‰€æœ‰åŸºäº PIL Image çš„å˜æ¢ï¼ˆå¦‚ Resize, RandomCrop, RandomHorizontalFlipï¼‰ä¹‹åã€‚`\n",
    "\n",
    "- `å®ƒå¿…é¡»åœ¨æ‰€æœ‰åŸºäº Tensor çš„å˜æ¢ï¼ˆå¦‚ Normalizeï¼‰ä¹‹å‰ã€‚`\n",
    "\n",
    "ä¸€ä¸ªå…¸å‹çš„é¡ºåºæ˜¯ï¼š\n",
    "- `[å°ºå¯¸/å¢å¼ºå˜æ¢ -> ToTensor() -> å½’ä¸€åŒ–å˜æ¢]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc06ee7-3729-4727-9051-c39a4c081c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ­£ç¡®çš„é¡ºåº\n",
    "correct_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(), # å…ˆè½¬ä¸º Tensor\n",
    "    transforms.Normalize(mean=[...], std=[...]) # å†å¯¹ Tensor åš Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ab232-f3e2-458b-bda7-6c271b6d663d",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "ToTensor() æ˜¯ä¸€ä¸ªçœ‹ä¼¼ç®€å•ä½†åŠŸèƒ½æå…¶é‡è¦çš„è½¬æ¢å™¨ã€‚è¯·ç‰¢è®°å®ƒçš„ä¸‰ä¸ªæ ¸å¿ƒä½œç”¨ï¼š\n",
    "\n",
    "- `1ã€è½¬ç±»å‹ï¼š å˜ä¸º torch.FloatTensorã€‚`\n",
    "\n",
    "- `2ã€ç¼©æ•°å€¼ï¼š åƒç´ èŒƒå›´ä» [0, 255] å˜ä¸º [0.0, 1.0]ã€‚`\n",
    "\n",
    "- `3ã€æ¢ç»´åº¦ï¼š å›¾åƒç»´åº¦ä» HWC å˜ä¸º CHWã€‚`\n",
    "\n",
    "æ­£ç¡®ç†è§£å’Œä½¿ç”¨ ToTensor() æ˜¯æ„å»ºä»»ä½• PyTorch è®¡ç®—æœºè§†è§‰æ¨¡å‹æ•°æ®ç®¡é“çš„å¿…å¤‡åŸºç¡€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa6823-f668-40bf-b1f0-d8196421050b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075e7bf-18e1-4113-b0d2-aa02f073a8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f54c3-2eb3-4838-b1eb-228458c18a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a865711-11e7-4963-b5ab-14a873f31871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac835e9-154e-4513-ad47-c092b5910002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f794f02a-bd0b-4709-9161-229b23fee440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b53b8-7d1e-4322-8547-9ecfa5495322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a2695-380f-4cc7-a3b7-6566a12e0ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
