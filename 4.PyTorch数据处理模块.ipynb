{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79186697-5f7a-4256-9554-73463081ffd9",
   "metadata": {},
   "source": [
    "# 🔹 4. 数据处理模块\n",
    "\n",
    "### 1、torch.utils.data.Dataset：定义自定义数据集\n",
    "\n",
    "### 2、torch.utils.data.DataLoader：批量加载数据\n",
    "\n",
    "### 3、torchvision.datasets：常用数据集（MNIST、CIFAR、ImageNet 等）\n",
    "\n",
    "### 4、torchvision.transforms：图像预处理（裁剪、缩放、归一化、增强等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d83f6-011f-413a-a25c-e32b8996c911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4edc355c-3fe8-47a0-b58a-ca4620222b81",
   "metadata": {},
   "source": [
    "# 1、torch.utils.data.Dataset：定义自定义数据集\n",
    "## ⚠️ 核心概念：Dataset 是什么？\n",
    "torch.utils.data.Dataset 是一个 抽象类 (abstract class)，它代表了一个数据集。在 PyTorch 中，所有自定义的数据集都应该继承这个类。\n",
    "\n",
    "它的核心思想是 将数据的具体存储、访问方式与模型的训练过程解耦。\n",
    "\n",
    "✅ 数据集 (Dataset)：\\\n",
    "负责回答两个最基本的问题：“我的数据集里一共有多少个样本？” (__len__) 和 “请给我第 i 个样本” (__getitem__)。它只关心单个数据样本的获取和预处理。\n",
    "\n",
    "✅ 数据加载器 (DataLoader)：\\\n",
    "负责从 Dataset 中取出数据，并把它们打包成一个个批次 (batch)，同时还可以进行数据打乱 (shuffle) 和多进程加载等操作，高效地喂给模型进行训练。\n",
    "\n",
    "简单来说，Dataset 定义了数据的来源和单一样本的处理方式，而 DataLoader 则在此基础上构建了高效的数据流。\n",
    "\n",
    "---\n",
    "\n",
    "## 👉 如何使用 Dataset：三大要素\n",
    "要创建一个自定义的 Dataset，你只需要继承 torch.utils.data.Dataset 并重写 (override) 以下三个方法：\n",
    "\n",
    "### 🧭 _ _init_ _(self, ...): 构造函数。\n",
    "\n",
    "作用：执行数据集的初始化操作。这通常包括加载数据索引（比如图片路径和对应的标签）、定义数据变换 (transform) 等。\n",
    "\n",
    "建议：在这个阶段，不要 加载所有的数据到内存中（除非你的数据集非常小）。通常只加载元信息（metadata），比如文件路径列表，这样可以节省大量内存。\n",
    "\n",
    "### 🧭 _ _len_ _(self): 返回数据集的样本总数。\n",
    "\n",
    "作用：DataLoader 需要知道数据集的总大小，以便确定迭代的次数、如何进行索引以及如何生成批次。\n",
    "\n",
    "实现：通常是返回你在 __init__ 中加载的索引列表的长度。\n",
    "\n",
    "### 🧭 _ _getitem_ _(self, index): 根据索引 index 获取并返回一个数据样本。\n",
    " \n",
    "作用：这是 Dataset 的核心。DataLoader 会根据需要，传入一个索引 index，这个方法则需要根据这个索引定位到具体的数据文件，读取它，进行必要的预处理（如图像缩放、裁剪、归一化、转换成 Tensor 等），最后返回处理好的数据样本（通常是一个元组，例如 (data_tensor, label_tensor)）。\n",
    "\n",
    "关键：真正的数据加载和转换（I/O 操作和计算）发生在这里，实现了“按需加载”，非常高效。\n",
    "\n",
    "---\n",
    "\n",
    "### 代码示例：自定义一个图像数据集\n",
    "假设我们有如下的文件夹结构，用于一个简单的猫狗分类任务：\n",
    "\n",
    "```\n",
    "data/\n",
    "├── cats/\n",
    "│   ├── cat.0.jpg\n",
    "│   ├── cat.1.jpg\n",
    "│   └── ...\n",
    "└── dogs/\n",
    "    ├── dog.0.jpg\n",
    "    ├── dog.1.jpg\n",
    "    └── ...\n",
    "```\n",
    "### 现在，我们来创建一个自定义的 Dataset 来加载这些数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1cb10-59d0-40f0-b594-b8a3522d7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image # 用于读取图片\n",
    "\n",
    "class CatsAndDogsDataset(Dataset):\n",
    "    \"\"\"自定义猫狗分类数据集\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 包含 'cats' 和 'dogs' 文件夹的根目录。\n",
    "            transform (callable, optional): 应用于样本的可选变换。\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []  # 用于存储 (图片路径, 标签) 的列表\n",
    "\n",
    "        # 为猫和狗分配标签\n",
    "        # cats -> 0, dogs -> 1\n",
    "        for label, class_name in enumerate(['cats', 'dogs']):\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, file_name)\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集中样本的总数。\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        根据索引 index 获取一个样本。\n",
    "        \"\"\"\n",
    "        # 1. 从 self.samples 中获取图片路径和标签\n",
    "        img_path, label = self.samples[index]\n",
    "\n",
    "        # 2. 读取图片\n",
    "        # 使用 'L' 转换为灰度图，'RGB' 转换为彩色图\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # 3. 如果定义了变换，则对图片进行变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # 4. 将标签也转换为 Tensor (可选，但推荐)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        # 5. 返回处理好的图片 Tensor 和标签 Tensor\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a33d19-a630-449c-b06d-7e74b23fd9e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ⚠️ Dataset 与 DataLoader 的协同工作\n",
    "Dataset 本身只是一个数据访问的接口，它一次只能通过 [] 索引返回一个样本。要实现高效的训练，我们需要 DataLoader。\n",
    "\n",
    "DataLoader 会从 Dataset 中自动拉取数据，并完成以下关键工作：\n",
    "\n",
    "- `批量处理 (Batching)：将多个样本打包成一个批次 (batch)。`\n",
    "\n",
    "- `数据打乱 (Shuffling)：在每个 epoch 开始时，随机打乱数据顺序，以增强模型的泛化能力。`\n",
    "\n",
    "- `并行加载 (Parallel Loading)：使用多个子进程 (num_workers) 同步加载数据，避免数据加载成为 GPU 计算的瓶颈。`\n",
    "\n",
    "---\n",
    "\n",
    "### 使用示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4f42c-e5b2-4bae-b098-919e849951ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. 定义数据变换\n",
    "# 这里我们定义了一个简单的变换：将图片缩放到 224x224，然后转换为 Tensor\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 标准化\n",
    "])\n",
    "\n",
    "# 2. 实例化我们自定义的 Dataset\n",
    "dataset_path = 'data/'\n",
    "custom_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=data_transform)\n",
    "print(f\"数据集大小: {len(custom_dataset)}\")\n",
    "\n",
    "# 3. 实例化 DataLoader\n",
    "# - dataset: 我们创建的数据集实例\n",
    "# - batch_size: 每个批次包含的样本数\n",
    "# - shuffle: 是否在每个 epoch 开始时打乱数据\n",
    "# - num_workers: 用于数据加载的子进程数量\n",
    "data_loader = DataLoader(dataset=custom_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# 4. 在训练循环中使用 DataLoader\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    # DataLoader 是一个可迭代对象\n",
    "    for batch_images, batch_labels in data_loader:\n",
    "        # 在这里，batch_images 的形状通常是 (batch_size, channels, height, width)\n",
    "        # batch_labels 的形状通常是 (batch_size)\n",
    "        \n",
    "        # 接下来就可以将这些批次数据送入模型进行训练\n",
    "        # model(batch_images) ...\n",
    "        \n",
    "        print(f\"  - 批次图像形状: {batch_images.shape}\")\n",
    "        print(f\"  - 批次标签形状: {batch_labels.shape}\")\n",
    "        break # 这里只演示一个批次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98a869-e460-4058-945b-c70bbf44db74",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ⚠️ 两种类型的 Dataset\n",
    "PyTorch 提供了两种主要类型的 Dataset：\n",
    "\n",
    "1、Map-style Datasets:\n",
    "\n",
    "- `我们上面实现的就属于这种。`\n",
    "- `它实现了 __getitem__() 和 __len__() 方法。`\n",
    "- `它代表了从索引 (integer)到数据样本的映射 (map)。`\n",
    "- `这是最常用的一种。`\n",
    "\n",
    "2、Iterable-style Datasets:\n",
    "\n",
    "- `它实现了 __iter__() 方法。`\n",
    "- `它代表了数据样本的一个可迭代对象 (iterable)，类似于 Python 的生成器。`\n",
    "- `当你无法事先知道数据集的总长度，或者数据是从流中读取时（例如，从数据库或远程服务器持续读取），这种类型非常有用。`\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结\n",
    "torch.utils.data.Dataset 是 PyTorch 中构建数据输入管道的基石，它定义了如何获取单个数据样本。\n",
    "\n",
    "通过继承它并实现 __init__、__len__ 和 __getitem__ 这三个核心方法，你可以为任何类型的数据创建自定义的加载逻辑。\n",
    "\n",
    "Dataset 必须与 DataLoader 配合使用，DataLoader 在 Dataset 的基础上提供了批处理、数据打乱和并行加载等高级功能，是构建高效、可读性强的数据管道的标准做法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ba47c-20a8-4edb-93ff-71a8b54038a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234af2c0-4ed8-4fa2-bc29-87cc195e6521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49ac7744-e20d-47ef-8d5d-e3be4f79e63b",
   "metadata": {},
   "source": [
    "# 2、torch.utils.data.DataLoader。\n",
    "\n",
    "如果说 Dataset 是一个“数据仓库”，定义了数据的总量和获取单个数据的方法，那么 DataLoader 就是一个高效的“数据搬运工”，负责从仓库中取出数据，经过智能打包和运输，高效地送达“模型”这个工厂。\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 核心概念：DataLoader 是什么？\n",
    "torch.utils.data.DataLoader 是一个 Python 可迭代对象 (iterable)。它将一个 Dataset 对象包装起来，为我们提供了一种简单、高效、可定制的方式来迭代访问数据集。\n",
    "\n",
    "它解决了 Dataset 无法直接处理的几个关键问题，使得大规模数据训练成为可能：\n",
    "\n",
    "- `批量处理 (Batching)：\n",
    "模型训练通常采用小批量随机梯度下降 (mini-batch SGD)，一次处理一小批数据而不是单个样本。DataLoader 自动将从 Dataset 中取出的单个样本打包成一个批次 (batch)。`\n",
    "\n",
    "- `数据打乱 (Shuffling)：\n",
    "为了让模型有更好的泛化能力，避免过拟合，我们需要在每个训练周期 (epoch) 开始时打乱数据顺序。DataLoader 可以通过一个简单的参数 shuffle=True 实现这一点。`\n",
    "\n",
    "- `并行加载 (Parallel Loading)：\n",
    "数据加载（从硬盘读取、预处理）通常是 CPU 密集型任务。如果串行加载，GPU 可能会花费大量时间等待 CPU 准备好数据，造成“算力饥饿”。DataLoader 可以使用多个子进程 (num_workers) 在后台并行加载数据，让数据准备和模型计算同时进行，极大地提升了训练效率。`\n",
    "\n",
    "- `数据整合 (Collation)：\n",
    "将多个独立的样本组合成一个批次张量 (batch tensor) 的过程。DataLoader 有默认的整合逻辑，也支持用户自定义。`\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 核心参数详解\n",
    "DataLoader 的构造函数有很多参数，我们来讲解其中最重要、最常用的几个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c45ce-fdcc-4040-87d8-d3301e7834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc71a48-9ef5-4ed8-9b2e-189e2fb1dcdd",
   "metadata": {},
   "source": [
    "## 参数详解\n",
    "---\n",
    "#### `dataset`（必需）\n",
    "- **类型**：`torch.utils.data.Dataset` 对象  \n",
    "- **作用**：指定数据来源，是 `DataLoader` 的数据源。必须传入一个继承自 `Dataset` 的实例。\n",
    "\n",
    "---\n",
    "\n",
    "#### `batch_size`\n",
    "- **类型**：`int`，默认为 `1`  \n",
    "- **作用**：定义每个批次包含的样本数量。  \n",
    "- **建议**：根据 GPU 显存和模型复杂度调整，常见值为 `16`, `32`, `64`, `128`。\n",
    "\n",
    "---\n",
    "#### `shuffle`\n",
    "- **类型**：`bool`，默认为 `False`  \n",
    "- **作用**：是否在每个 epoch 开始时打乱数据顺序。  \n",
    "- **建议**：\n",
    "  - ✅ 训练时：`True`（提升模型泛化能力）\n",
    "  - ❌ 验证/测试时：`False`（保证评估一致性）\n",
    "\n",
    "---\n",
    "\n",
    "#### `num_workers`\n",
    "- **类型**：`int`，默认为 `0`  \n",
    "- **作用**：用于数据加载的子进程数量。\n",
    "  - `0`：所有数据在主进程中加载（同步）。\n",
    "  - `> 0`：使用多个子进程异步加载数据，提升速度。\n",
    "- **建议**：\n",
    "  - 一般设为 `4`, `8`, `16`，建议不超过 CPU 核心数。\n",
    "  - Windows 上注意避免 `num_workers > 0` 导致的 `freeze_support` 问题（建议在 `if __name__ == '__main__':` 中运行）。\n",
    "\n",
    "---\n",
    "\n",
    "#### `pin_memory`\n",
    "- **类型**：`bool`，默认为 `False`  \n",
    "- **作用**：若为 `True`，将数据加载到“固定内存”（pinned memory），加快从 CPU 到 GPU 的传输速度。  \n",
    "- **建议**：\n",
    "  - ✅ 使用 GPU 训练时：强烈建议设为 `True`\n",
    "  - ❌ CPU 训练时：无需开启\n",
    "\n",
    "---\n",
    "\n",
    "#### `drop_last`\n",
    "- **类型**：`bool`，默认为 `False`  \n",
    "- **作用**：当样本总数不能被 `batch_size` 整除时，最后一个批次样本数会不足。若设为 `True`，则丢弃这个不完整的批次。  \n",
    "- **应用场景**：\n",
    "  - 某些模型要求输入尺寸固定（如部分 RNN、GAN）\n",
    "  - 批归一化（BatchNorm）在小批次上不稳定时\n",
    "\n",
    "---\n",
    "\n",
    "#### `collate_fn`\n",
    "- **类型**：可调用函数（`callable`），默认为 `None`  \n",
    "- **作用**：自定义如何将多个样本组合成一个批次。默认函数会将张量堆叠（`torch.stack`）。  \n",
    "- **默认行为**：\n",
    "  ```python\n",
    "  # 默认 collate_fn 会做类似操作\n",
    "  batch = {\n",
    "      'images': torch.stack([s['image'] for s in samples]),\n",
    "      'labels': torch.tensor([s['label'] for s in samples])\n",
    "  }\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 使用建议总结\n",
    "\n",
    "| 参数 | 训练模式建议 | 验证/测试建议 |\n",
    "|------|---------------|----------------|\n",
    "| `shuffle` | `True` | `False` |\n",
    "| `num_workers` | `4~16`（根据 CPU） | `4~8` |\n",
    "| `pin_memory` | `True`（GPU） | `True`（GPU） |\n",
    "| `drop_last` | `True`（若模型敏感） | `False` |\n",
    "| `collate_fn` | 按需自定义 | 按需自定义 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f537648-afac-4e13-baae-b2c2a1096201",
   "metadata": {},
   "source": [
    "## 🔄 DataLoader 工作流程详解\n",
    "当你开始在一个 DataLoader 上进行迭代时（例如：for batch in data_loader:），其内部会自动执行一系列高效的操作，实现数据加载与模型训练的流水线并行。整个流程如下：\n",
    "\n",
    "### 1️⃣ 生成索引（Index Generation）\n",
    "DataLoader 首先通过一个 Sampler（采样器） 生成当前批次所需的样本索引列表。\\\n",
    "根据 shuffle 参数选择不同的采样策略：\n",
    "- `✅ shuffle=True → 使用 RandomSampler（随机打乱顺序）`\n",
    "- `❌ shuffle=False → 使用 SequentialSampler（按顺序采样）`\n",
    "这些索引决定了本次需要加载哪些样本。\n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ 分发任务（Task Distribution）\n",
    "如果设置了 num_workers > 0，DataLoader 会将这批索引分发给多个子进程（worker processes）。\\\n",
    "每个子进程负责加载一部分数据，实现任务并行化。\n",
    "\n",
    "---\n",
    "\n",
    "### 3️⃣ 并行加载（Parallel Data Loading）\n",
    "每个子进程独立执行：\n",
    "\n",
    "dataset[index]\n",
    "\n",
    "- `即调用 Dataset 的 __getitem__ 方法。`\n",
    "\n",
    "加载过程包括：`\n",
    "- `文件读取（如图像、文本）`\n",
    "- `数据解码（如 PIL 加载图片）`\n",
    "- `应用 transform 进行预处理`\n",
    "- `所有子进程并行运行，显著提升 I/O 效率，避免成为训练瓶颈。`\n",
    "\n",
    "---\n",
    "\n",
    "### 4️⃣ 整合数据（Collation）\n",
    "主进程收集所有子进程返回的单个样本，组成一个列表：\n",
    "\n",
    "batch_list = [sample_1, sample_2, ..., sample_batch_size]\n",
    "\n",
    "然后调用 collate_fn 函数，将该列表整合为一个完整的批次：\\\n",
    "🔹 默认行为：使用 torch.stack() 将张量堆叠成一个大张量。\\\n",
    "🔹 自定义需求：对于变长数据（如 NLP 句子），需自定义 collate_fn 实现 padding 或 packing。\\\n",
    "输出通常为 (inputs, labels) 元组或字典形式。\n",
    "\n",
    "---\n",
    "\n",
    "### 5️⃣ 返回批次（Yield Batch）\n",
    "整合后的批次数据通过 yield 返回给训练循环。\\\n",
    "⚡ 关键优势：在主进程进行前向传播、反向传播等计算的同时，子进程已在后台加载下一个批次的数据，形成“流水线并行（Pipelining）”，最大化 GPU 利用率。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdfb60d-7d99-4105-9807-277a8a112fb9",
   "metadata": {},
   "source": [
    "---\n",
    "### 代码示例\n",
    "我们继续使用之前定义的 CatsAndDogsDataset。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69962f0-ca95-491e-8cdb-c33919fdaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 假设 CatsAndDogsDataset 类已经在这里定义好了\n",
    "# class CatsAndDogsDataset(Dataset):\n",
    "#     ...\n",
    "\n",
    "# 1. 定义数据变换\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. 实例化 Dataset\n",
    "dataset_path = 'data/'\n",
    "train_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=data_transform)\n",
    "\n",
    "# 3. 实例化 DataLoader，并配置核心参数\n",
    "# 这是训练集加载器，所以 shuffle=True\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,       # 每个批次加载 64 张图片\n",
    "    shuffle=True,        # 每个 epoch 都打乱数据\n",
    "    num_workers=4,       # 使用 4 个子进程来加载数据\n",
    "    pin_memory=True      # 如果使用 GPU，设置为 True\n",
    ")\n",
    "\n",
    "# 4. 在训练循环中使用 DataLoader\n",
    "print(f\"开始遍历 train_loader...\")\n",
    "# DataLoader 是一个迭代器，我们可以像遍历列表一样遍历它\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    # 将数据移动到 GPU (如果可用)\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # images = images.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    \n",
    "    # 打印批次数据的形状\n",
    "    print(f\"批次 {i+1}:\")\n",
    "    print(f\"  - 图像批次的形状: {images.shape}\")  # torch.Size([64, 3, 224, 224])\n",
    "    print(f\"  - 标签批次的形状: {labels.shape}\")  # torch.Size([64])\n",
    "\n",
    "    # 在这里，可以将 images 和 labels 送入模型进行训练\n",
    "    # e.g., outputs = model(images)\n",
    "    #        loss = criterion(outputs, labels)\n",
    "    #        ...\n",
    "\n",
    "    # 为了演示，我们只遍历几个批次就退出\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889b521-a466-4d59-b3bf-de7d2fc4d712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e935ab7-6a15-4d03-9ee5-32a44dece253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc8e808-35fc-4675-9e0c-ce02bdbc2fd6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ece21-ddb4-4011-bc4d-df780290fc9e",
   "metadata": {},
   "source": [
    "# 4、torchvision.transforms。\n",
    "在 Dataset 负责定位和读取原始数据、DataLoader 负责打包和加载数据之后，transforms 则负责在数据送入模型前，对原始数据（通常是 PIL Image 对象）进行一系列的“加工处理”。\n",
    "\n",
    "## ⚡ 核心概念：transforms 是什么？\n",
    "torchvision.transforms 模块包含了一系列常见的图像变换操作。这些操作可以被串联起来，形成一个处理流水线。它的核心作用主要有两个：\n",
    "\n",
    "### 1、数据预处理 (Data Preprocessing)：\n",
    "\n",
    "- `神经网络要求输入的数据具有固定的尺寸、格式和数据范围。例如，一个预训练模型可能要求所有输入图片都是 224x224 像素，并且是 torch.Tensor 类型，像素值也需要经过归一化。transforms 就是用来完成这些标准化工作的。`\n",
    "\n",
    "- ⚠️`关键步骤：尺寸调整、转换成张量 (Tensor)、数据归一化。`\n",
    "\n",
    "### 2、数据增强 (Data Augmentation)：\n",
    "\n",
    "- `这是提升模型性能和泛化能力的关键技术。通过对训练图像进行一系列随机的变换（如随机翻转、旋转、裁剪、色彩抖动等），我们可以凭空创造出更多样化的训练样本。`\n",
    "\n",
    "- `这相当于扩充了训练集，让模型在训练时看到“千变万化”的图像，从而学习到更本质、更鲁棒的特征，有效防止过拟合。`\n",
    "\n",
    "- `重要原则：数据增强只应在训练集 (training set) 上使用。在验证集 (validation set) 和测试集 (test set) 上，我们只需要进行必要的预处理，以确保评估结果的一致性和可复现性。`\n",
    "\n",
    "---\n",
    "\n",
    "## 如何使用：transforms.Compose\n",
    "transforms 模块中最常用的一个类是 transforms.Compose。它的作用就像一个容器，可以将多个变换操作串联成一个序列。当你调用这个 Compose 对象时，它会按照你定义的顺序，依次对输入的图像执行每一个变换。\n",
    "\n",
    "### 基本用法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150e2e7-ef21-440e-a627-006be7b73532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 定义一个变换序列\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),             # 1. 先把图片尺寸缩放到 256x256\n",
    "    transforms.CenterCrop(224),         # 2. 然后从中心裁剪出 224x224 的区域\n",
    "    transforms.ToTensor(),              # 3. 转换为 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 4. 进行归一化\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 使用\n",
    "# from PIL import Image\n",
    "# image = Image.open(\"path/to/your/image.jpg\")\n",
    "# transformed_image = data_transform(image) # 应用变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22951d9e-153e-4408-8dd5-84f6de89babd",
   "metadata": {},
   "source": [
    "## 常用 transforms 分类详解\n",
    "下面我们分类介绍一些最常用的变换功能。\n",
    "\n",
    "1. 尺寸与裁剪 (Sizing and Cropping)\n",
    "- `transforms.Resize(size): 将输入图像的尺寸调整为指定大小。size 可以是一个整数（短边缩放到该尺寸，长边等比缩放）或一个元组 (h, w)。`\n",
    "\n",
    "- `transforms.CenterCrop(size): 从图像中心裁剪出指定大小的区域。`\n",
    "\n",
    "- `transforms.RandomCrop(size, padding=None): 从一个随机位置裁剪出指定大小的区域。常用于数据增强。`\n",
    "\n",
    "- `transforms.RandomResizedCrop(size, scale=(0.08, 1.0)): 这是训练时非常常用且强大的一个变换。它会随机裁剪原始图像的一个区域（裁剪面积和长宽比都是随机的），然后将这个区域缩放到指定大小。这模拟了物体在不同尺度和位置出现的情况。`\n",
    "\n",
    "2. 翻转与旋转 (Flipping and Rotation)\n",
    "- `transforms.RandomHorizontalFlip(p=0.5): 以 p 的概率（默认为 0.5）对图像进行水平翻转。`\n",
    "\n",
    "- `transforms.RandomVerticalFlip(p=0.5): 以 p 的概率对图像进行垂直翻转。`\n",
    "\n",
    "- `transforms.RandomRotation(degrees): 在 (-degrees, +degrees) 范围内随机旋转图像。`\n",
    "\n",
    "3. 类型转换与归一化 (Crucial Steps)\n",
    "- `transforms.ToTensor(): 这是至关重要的一步，它做了三件事：`\n",
    "\n",
    "- 1、 `将输入的 PIL Image 或 numpy.ndarray 转换成 torch.Tensor。`\n",
    "\n",
    "- 2、 `将像素值从 [0, 255] 的范围缩放到 [0.0, 1.0] 的范围。`\n",
    "\n",
    "- 3、 `将图像的维度顺序从 (H, W, C) (高, 宽, 通道) 改变为 (C, H, W) (通道, 高, 宽)，这是 PyTorch 模型期望的输入格式。`\n",
    "\n",
    "- `transforms.Normalize(mean, std): 用给定的均值 (mean) 和标准差 (std) 对张量图像进行归一化。`\n",
    "\n",
    "公式：output=(input−mean)/std\n",
    "\n",
    "- `作用：使不同通道的像素值分布在相似的范围内，这有助于加速模型收敛。`\n",
    "\n",
    "- `mean 和 std 都是一个包含 C 个元素（对应 C 个通道）的序列。对于在 ImageNet 数据集上预训练的模型，通常使用以下值：`\n",
    "\n",
    "- `mean=[0.485, 0.456, 0.406]`\n",
    "\n",
    "- `std=[0.229, 0.224, 0.225]`\n",
    "\n",
    "4. 色彩与亮度 (Color Augmentation)\n",
    "- `transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0): 随机改变图像的亮度、对比度、饱和度和色调。这是非常有效的颜色数据增强方法。`\n",
    "\n",
    "- `transforms.Grayscale(num_output_channels=1): 将图像转换为灰度图。`\n",
    "\n",
    "---\n",
    "\n",
    "## 实战：为训练集和验证集构建不同的处理流\n",
    "这是一个最佳实践，展示了如何为训练和验证/测试阶段定义不同的 transforms 管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd2ea3-20b6-40cf-a64f-23227673cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# 假设我们有之前定义的 CatsAndDogsDataset\n",
    "\n",
    "# 1. 为训练集定义变换：包含数据增强\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # 随机裁剪和缩放\n",
    "    transforms.RandomHorizontalFlip(),    # 随机水平翻转\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # 随机颜色抖动\n",
    "    transforms.ToTensor(),                # 转换为 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 归一化\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. 为验证集/测试集定义变换：只做必要的预处理\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),             # 缩放\n",
    "    transforms.CenterCrop(224),         # 中心裁剪\n",
    "    transforms.ToTensor(),                # 转换为 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 归一化\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# 3. 在创建 Dataset 实例时传入对应的 transforms\n",
    "dataset_path = 'data/'\n",
    "\n",
    "# 训练集使用带数据增强的变换\n",
    "train_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=train_transforms)\n",
    "\n",
    "# 验证集使用固定的预处理变换\n",
    "val_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=val_test_transforms)\n",
    "\n",
    "\n",
    "# 4. 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4) # 验证集不需要 shuffle\n",
    "\n",
    "# 现在，从 train_loader 中取出的每个批次都是经过随机增强的，而 val_loader 中的数据则是确定性的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e70f2b-658c-4d07-8f75-32ca809098a8",
   "metadata": {},
   "source": [
    "---\n",
    "# 总结\n",
    "torchvision.transforms 是构建计算机视觉数据管道的核心组件。\n",
    "\n",
    "它的两大职责是数据预处理（使数据符合模型输入要求）和数据增强（提升模型泛化能力）。\n",
    "\n",
    "使用 transforms.Compose 可以方便地将多个操作链接成一个处理流水线。\n",
    "\n",
    "ToTensor() 和 Normalize() 是几乎所有图像预处理流程中都必不可少的步骤。\n",
    "\n",
    "#### ⚠️务必记住：\n",
    "为训练集和验证/测试集设置不同的变换流程，数据增强只用于训练集。这套 Dataset + DataLoader + transforms \n",
    "的组合拳是所有 PyTorch 视觉任务的标准起点。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8728b4-e438-43df-8588-62b8a443c23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0b36041-17dd-4390-8efa-056265fe4282",
   "metadata": {},
   "source": [
    "# torchvision.transforms.ToTensor()\n",
    "堪称是“守门员”和“格式转换官”，是连接图像世界（PIL, NumPy）和 PyTorch 张量世界（Tensor）最关键的桥梁。理解它的具体工作方式至关重要。\n",
    "\n",
    "## 核心概述\n",
    "transforms.ToTensor() 的主要功能是将一个 PIL Image 对象或一个 numpy.ndarray 对象转换为 torch.Tensor。\n",
    "\n",
    "然而，这个转换过程并非简单的类型强制转换，它精确地执行了三个核心操作。\n",
    "\n",
    "---\n",
    "## ToTensor() 的三大核心操作\n",
    "### 1. 转换数据类型 (Convert Data Type)\n",
    "- `它会将输入的 PIL 图像或 NumPy 数组转换为 torch.FloatTensor。这意味着输出的张量将是32位浮点数类型，这是神经网络进行计算所期望的标准类型。`\n",
    "\n",
    "### 2. 归一化像素值 (Normalize Pixel Values)\n",
    "- `这是非常重要的一步。原始图像的像素值通常存储为 uint8 类型，范围在 [0, 255] 之间。ToTensor() 会将这个范围等比例地缩放到 [0.0, 1.0] 之间。`\n",
    "\n",
    "实现方式：很简单，就是将每个像素值除以 255。\n",
    "\n",
    "- `为什么这么做：将数据缩放到一个较小的、标准化的范围（如 [0, 1] 或 [-1, 1]）有助于神经网络的稳定训练和快速收敛。[0, 1] 是最常见的起点。`\n",
    "\n",
    "### 3. 调整维度顺序 (Adjust Dimension Order)\n",
    "这是初学者最容易混淆、也最需要注意的一点。\n",
    "\n",
    "- `输入格式 (图像世界)：对于一个标准的彩色图像，其数据通常以 HWC 格式存储，即 (Height, Width, Channels)。例如，一个 224x224 的 RGB 图像，其 NumPy 数组的形状会是 (224, 224, 3)。`\n",
    "\n",
    "- `输出格式 (PyTorch 世界)：PyTorch 中的卷积神经网络等模块期望的图像输入格式是 CHW，即 (Channels, Height, Width)。因此，ToTensor() 会自动重新排列维度。同一个 224x224 的 RGB 图像，转换后的张量形状会是 (3, 224, 224)。`\n",
    "\n",
    "### 总结一下维度的变化：\n",
    "| 输入类型      | 输入形状   | 输出形状  |\n",
    "|---------------|------------|-----------|\n",
    "| numpy.ndarray | H x W x C  | C x H x W |\n",
    "| PIL.Image     | (隐式 HWC) | C x H x W |\n",
    "                                  对于灰度图，H x W 会变为 1 x H x W，增加一个通道维度。\n",
    "\n",
    "---\n",
    "### 代码演示\n",
    "让我们通过一个具体的例子来看看这三个操作是如何发生的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee0f24-84f3-4129-b9b6-e793b2e24f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 1. 创建一个示例 NumPy 数组 (模拟一张 3x4 的 RGB 图片)\n",
    "# 形状为 HWC: (3, 4, 3)\n",
    "# 数据类型为 uint8, 范围 [0, 255]\n",
    "# 我们创建一个棋盘格模式以便观察\n",
    "numpy_image = np.array([\n",
    "    [[255, 0, 0], [255, 255, 0], [0, 255, 0], [0, 255, 255]],\n",
    "    [[0, 0, 255], [255, 0, 255], [0, 0, 0],   [127, 127, 127]],\n",
    "    [[50, 100, 150], [200, 150, 100], [75, 125, 175], [0, 50, 250]]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "print(f\"原始 NumPy 数组:\")\n",
    "print(f\"  - 类型: {numpy_image.dtype}\")\n",
    "print(f\"  - 形状: {numpy_image.shape}\")\n",
    "print(f\"  - 右上角像素值 (R,G,B): {numpy_image[0, 3, :]}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 2. 从 NumPy 数组创建 PIL Image 对象\n",
    "pil_image = Image.fromarray(numpy_image)\n",
    "print(f\"原始 PIL Image 对象:\")\n",
    "print(f\"  - 模式: {pil_image.mode}\")\n",
    "print(f\"  - 尺寸 (W, H): {pil_image.size}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# 3. 实例化并应用 ToTensor\n",
    "to_tensor_transform = transforms.ToTensor()\n",
    "tensor_from_numpy = to_tensor_transform(numpy_image)\n",
    "tensor_from_pil = to_tensor_transform(pil_image)\n",
    "\n",
    "# 4. 检查转换后的 Tensor (以 NumPy 转换结果为例)\n",
    "print(f\"转换后的 Tensor:\")\n",
    "print(f\"  - 类型: {tensor_from_numpy.dtype}\")\n",
    "print(f\"  - 形状: {tensor_from_numpy.shape}\") # 注意！形状从 (3, 4, 3) 变为 (3, 3, 4)\n",
    "print(f\"  - 右上角像素值 (R,G,B):\")\n",
    "# 访问方式变为 [channel, height, width]\n",
    "red_channel_val = tensor_from_numpy[0, 0, 3] # 红色通道\n",
    "green_channel_val = tensor_from_numpy[1, 0, 3] # 绿色通道\n",
    "blue_channel_val = tensor_from_numpy[2, 0, 3] # 蓝色通道\n",
    "print(f\"    - R: {red_channel_val:.4f} (原始值 0 / 255)\")\n",
    "print(f\"    - G: {green_channel_val:.4f} (原始值 255 / 255)\")\n",
    "print(f\"    - B: {blue_channel_val:.4f} (原始值 255 / 255)\")\n",
    "\n",
    "# 验证两个转换结果是否一致\n",
    "assert torch.equal(tensor_from_numpy, tensor_from_pil)\n",
    "print(\"\\n从 NumPy 和 PIL 转换的 Tensor 结果一致。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556f7a7-b143-4975-bc9a-021aa5c4e175",
   "metadata": {},
   "source": [
    "### 输出分析：\n",
    "\n",
    "- `类型变化: uint8 -> torch.float32。`\n",
    "\n",
    "- `形状变化: (3, 4, 3) -> torch.Size([3, 3, 4])，完美展示了 HWC -> CHW 的维度重排。`\n",
    "\n",
    "- `值缩放: 原始值 [0, 255, 255] 经过除以 255 后，变为了 [0.0, 1.0, 1.0]。`\n",
    "\n",
    "---\n",
    "\n",
    "### 在 transforms.Compose 中的位置\n",
    "- `ToTensor() 在 Compose 管道中通常处于中间位置。`\n",
    "\n",
    "- `它必须在所有基于 PIL Image 的变换（如 Resize, RandomCrop, RandomHorizontalFlip）之后。`\n",
    "\n",
    "- `它必须在所有基于 Tensor 的变换（如 Normalize）之前。`\n",
    "\n",
    "一个典型的顺序是：\n",
    "- `[尺寸/增强变换 -> ToTensor() -> 归一化变换]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc06ee7-3729-4727-9051-c39a4c081c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正确的顺序\n",
    "correct_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(), # 先转为 Tensor\n",
    "    transforms.Normalize(mean=[...], std=[...]) # 再对 Tensor 做 Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ab232-f3e2-458b-bda7-6c271b6d663d",
   "metadata": {},
   "source": [
    "## 总结\n",
    "ToTensor() 是一个看似简单但功能极其重要的转换器。请牢记它的三个核心作用：\n",
    "\n",
    "- `1、转类型： 变为 torch.FloatTensor。`\n",
    "\n",
    "- `2、缩数值： 像素范围从 [0, 255] 变为 [0.0, 1.0]。`\n",
    "\n",
    "- `3、换维度： 图像维度从 HWC 变为 CHW。`\n",
    "\n",
    "正确理解和使用 ToTensor() 是构建任何 PyTorch 计算机视觉模型数据管道的必备基础。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa6823-f668-40bf-b1f0-d8196421050b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075e7bf-18e1-4113-b0d2-aa02f073a8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f54c3-2eb3-4838-b1eb-228458c18a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a865711-11e7-4963-b5ab-14a873f31871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac835e9-154e-4513-ad47-c092b5910002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f794f02a-bd0b-4709-9161-229b23fee440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b53b8-7d1e-4322-8547-9ecfa5495322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a2695-380f-4cc7-a3b7-6566a12e0ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
