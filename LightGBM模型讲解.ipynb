{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ce0faf-e0cd-4e95-ad9c-b222a894aef9",
   "metadata": {},
   "source": [
    "# 📘 LightGBM 全面介绍\n",
    "## 一、背景与发展\n",
    "LightGBM 是微软（Microsoft）DMTK（Distributed Machine Learning Toolkit）团队于 2017 年开源的基于 梯度提升决策树（GBDT） 的高效框架，目标是解决传统 GBDT 在大规模数据、高维稀疏数据处理上的效率问题。\n",
    "\n",
    "它专注于：\n",
    "\n",
    "大规模数据训练\n",
    "\n",
    "分布式学习\n",
    "\n",
    "更快、更小、更准"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b065a11-3e13-4635-8d77-3b5282f62245",
   "metadata": {},
   "source": [
    "# ✅ LGBMClassifier 参数详解表（按功能分类）\n",
    "| 参数名                    | 类型                | 默认值      | 含义           | 备注                                      |\n",
    "| ---------------------- | ----------------- | -------- | ------------ | --------------------------------------- |\n",
    "| **基础控制参数**             |                   |          |              |                                         |\n",
    "| `boosting_type`        | str               | 'gbdt'   | 提升类型（提升算法）   | 可选：`'gbdt'`, `'dart'`, `'goss'`, `'rf'` |\n",
    "| `num_leaves`           | int               | 31       | 单棵树的最大叶子节点数  | 控制模型复杂度，越大越容易过拟合                        |\n",
    "| `max_depth`            | int               | -1       | 树的最大深度       | -1 表示不限制深度                              |\n",
    "| `learning_rate`        | float             | 0.1      | 学习率          | 降低可以提升泛化能力，但训练更慢                        |\n",
    "| `n_estimators`         | int               | 100      | 弱学习器（树）的数量   | 通常需调参选择                                 |\n",
    "| `objective`            | str               | 'binary' | 目标函数         | 分类任务常用：`'binary'`, `'multiclass'`       |\n",
    "| `random_state`         | int               | None     | 随机种子         | 确保结果可复现                                 |\n",
    "| **数据处理参数**             |                   |          |              |                                         |\n",
    "| `class_weight`         | dict / 'balanced' | None     | 样本类别权重       | 适用于样本不平衡（如欺诈检测）                         |\n",
    "| `min_child_samples`    | int               | 20       | 每个叶子节点的最小样本数 | 过小容易过拟合                                 |\n",
    "| `min_child_weight`     | float             | 1e-3     | 子节点的最小权重和    | 防止样本权重过低的节点分裂                           |\n",
    "| `subsample`            | float             | 1.0      | 训练样本采样比例（行）  | 防止过拟合，通常设为 0.7\\~0.9                     |\n",
    "| `colsample_bytree`     | float             | 1.0      | 构建每棵树时列的采样比例 | 通常设为 0.7\\~0.9                           |\n",
    "| `reg_alpha`            | float             | 0.0      | L1正则化系数      | 控制模型复杂度（特征选择）                           |\n",
    "| `reg_lambda`           | float             | 0.0      | L2正则化系数      | 控制模型复杂度（权重缩小）                           |\n",
    "| **多类别任务相关参数**          |                   |          |              |                                         |\n",
    "| `num_class`            | int               | None     | 类别数量         | 多分类任务时必填                                |\n",
    "| **提升方式参数（dart, goss）** |                   |          |              |                                         |\n",
    "| `drop_rate`            | float             | 0.1      | DART 模式下的丢弃率 | 仅在 boosting\\_type='dart' 时使用            |\n",
    "| `top_rate`             | float             | 0.2      | GOSS 的前面比例   | 仅在 boosting\\_type='goss' 时使用            |\n",
    "| `other_rate`           | float             | 0.1      | GOSS 的其他比例   | 仅在 boosting\\_type='goss' 时使用            |\n",
    "| **模型训练控制**             |                   |          |              |                                         |\n",
    "| `n_jobs`               | int               | -1       | 并行线程数        | -1 表示使用全部核心                             |\n",
    "| `verbose`              | int               | 1        | 控制日志输出       | 0（静默），1（默认），2（详细）                       |\n",
    "\n",
    "### 🧭⚠ 注意：learning_rate 和 n_estimators 是强相关的——如果 learning_rate 提高，n_estimators 应该减少，否则容易过拟合。\n",
    "\n",
    "## 📊 、调参指南\n",
    "\n",
    "| 目的            | 推荐参数调整                                                |\n",
    "| ------------- | ----------------------------------------------------- |\n",
    "| 防止过拟合         | 减小 `num_leaves`、增加 `min_child_samples`、降低 `max_depth` |\n",
    "| 提高准确率         | 提高 `num_leaves`，减小 `learning_rate`，增加 `n_estimators`  |\n",
    "| 提高召回率（检测更多欺诈） | 增大 `scale_pos_weight` 或使用 `class_weight='balanced'`   |\n",
    "| 加快训练速度        | 减少 `n_estimators` 或使用较高 `learning_rate`（初期）           |\n",
    "| 特征选择可解释性      | 使用 `model.feature_importances_` 或 SHAP 可视化            |\n",
    "\n",
    "# LightGBM 高级调参技巧\n",
    "## 1. 理解核心参数\n",
    "| 参数                 | 作用        | 说明                          |\n",
    "| ------------------ | --------- | --------------------------- |\n",
    "| `num_leaves`       | 叶子节点数     | 控制模型复杂度，过大容易过拟合             |\n",
    "| `max_depth`        | 树最大深度     | 限制树深度，防止过拟合                 |\n",
    "| `learning_rate`    | 学习率       | 小学习率 + 多迭代通常效果更好            |\n",
    "| `min_data_in_leaf` | 叶子节点最小样本数 | 防止叶子过拟合，调大更稳定               |\n",
    "| `feature_fraction` | 特征子采样比例   | 减少过拟合，增加随机性                 |\n",
    "| `bagging_fraction` | 数据采样比例    | 减少过拟合，和 `bagging_freq` 配合使用 |\n",
    "| `bagging_freq`     | 数据采样频率    | 非零时启用bagging                |\n",
    "| `lambda_l1`        | L1 正则化系数  | 增加模型稀疏性，控制过拟合               |\n",
    "| `lambda_l2`        | L2 正则化系数  | 防止过拟合                       |\n",
    "\n",
    "## 2. 调参流程建议\n",
    "### 2.1 学习率与迭代次数\n",
    "先固定 num_leaves、max_depth 等复杂度参数，用较大学习率（如 0.1）跑出初步结果，找到大致需要的迭代次数。\n",
    "\n",
    "降低学习率（如 0.01~0.05）并增加迭代次数（>1000），提升模型精度。\n",
    "\n",
    "### 2.2 调整树的复杂度\n",
    "调整 num_leaves，注意一般建议不超过 2^(max_depth)，否则会出现过拟合。\n",
    "\n",
    "通过限制 max_depth 控制树的深度，防止生成过深树。\n",
    "\n",
    "通过 min_data_in_leaf 控制叶子节点上的最小样本数，避免过拟合。\n",
    "\n",
    "### 2.3 使用正则化\n",
    "加大 lambda_l1 和 lambda_l2 可以减少过拟合。\n",
    "\n",
    "对于稀疏数据，L1 正则化更有效。\n",
    "\n",
    "### 2.4 采样与随机性\n",
    "使用 feature_fraction 随机采样特征，减少模型过拟合。\n",
    "\n",
    "使用 bagging_fraction 和 bagging_freq 进行行采样，增加模型鲁棒性。\n",
    "\n",
    "## 3. 进阶参数调节\n",
    "| 参数                 | 建议范围     | 说明                  |\n",
    "| ------------------ | -------- | ------------------- |\n",
    "| `num_leaves`       | 31\\~512  | 控制树叶子数量，越大拟合越强，易过拟合 |\n",
    "| `max_depth`        | 5\\~15    | 树深度限制               |\n",
    "| `min_data_in_leaf` | 20\\~1000 | 叶子最小样本数             |\n",
    "| `feature_fraction` | 0.6\\~1.0 | 随机采样特征比例            |\n",
    "| `bagging_fraction` | 0.6\\~1.0 | 随机采样数据比例            |\n",
    "| `bagging_freq`     | 1\\~10    | 采样频率                |\n",
    "| `lambda_l1`        | 0\\~5     | L1 正则化强度            |\n",
    "| `lambda_l2`        | 0\\~5     | L2 正则化强度            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d084f1-3cd0-4460-99ac-401e2e09acfb",
   "metadata": {},
   "source": [
    "## 二、核心特点（对比传统 GBDT）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52152c6-6f57-45df-8210-b7cc182b5774",
   "metadata": {},
   "source": [
    "| 特性     | LightGBM 优势                        |\n",
    "| ------ | ---------------------------------- |\n",
    "| 构建策略   | **基于 Leaf-wise（叶子优先）**             |\n",
    "| 样本分桶   | **基于直方图的决策树算法（Histogram）**，降低计算与内存 |\n",
    "| 特征处理   | 支持原生类别特征，不需独热编码                    |\n",
    "| 并行能力   | 支持 **特征并行** 和 **数据并行**             |\n",
    "| 稀疏数据处理 | 自动识别稀疏特征，优化处理                      |\n",
    "| 多分类    | 原生支持多分类任务                          |\n",
    "| 分布式训练  | 支持大数据多机训练（MPI, socket）             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db1a1d-05a4-4388-be0c-eb5352f7eafe",
   "metadata": {},
   "source": [
    "## 三、工作原理（简要）\n",
    "#### 📌 基于 GBDT 的 Boosting 迭代流程：\n",
    "每一轮迭代拟合残差：\n",
    "\n",
    "y = f0(x) + f1(x) + f2(x) + ... + fn(x)\n",
    "\n",
    "其中 fn(x) 是通过拟合上一次残差得到的新树。\n",
    " \n",
    "### 1. 📌 构建直方图（Histogram-based）\n",
    "将连续特征离散化为有限个桶（bins），在训练过程中操作的是桶而不是原始值，\n",
    "\n",
    "使用离散值代替原始浮点数，极大减少计算复杂度和内存。\n",
    "\n",
    "### 2. 📌 Leaf-wise 增长策略（vs. Level-wise）\n",
    "传统 GBDT 使用 Level-wise（（如 XGBoost）：一层一层地扩展，每层所有节点都扩展。）\n",
    "\n",
    "LightGBM 使用 Leaf-wise（选择当前增益最大的叶子节点进行分裂）\n",
    "\n",
    "优点：提高精度，减少误差,收敛更快；\n",
    "\n",
    "缺点：树的深度可能不平衡，容易过拟合（可通过限制最大深度防止）\n",
    "\n",
    "### 3. 📌 支持原生类别特征（categorical）：\n",
    "LightGBM 能识别并自动处理 category 类型，无需人工进行独热编码或 LabelEncoding。\n",
    "\n",
    "更快、更少内存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd5829-e40f-479e-96d1-ba5b0b72262f",
   "metadata": {},
   "source": [
    "## 四、常见参数分类汇总"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e9df8-2f16-46f6-97e0-4131a79d4b39",
   "metadata": {},
   "source": [
    "### 📌 1. 基础参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced6ed3-d0ef-4303-8095-464c775a8eb8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "| 参数                        | 作用               | 示例                              |\n",
    "| ------------------------- | ---------------- | ------------------------------- |\n",
    "| `boosting_type`           | 提升类型（默认为 'gbdt'） | gbdt、dart、goss、rf               |\n",
    "| `objective`               | 目标函数             | regression（回归）、binary(二分类)、multiclass(多分类)    |\n",
    "| `metric`                  | 评估指标             | auc、logloss、rmse、multi\\_logloss |\n",
    "| `learning_rate`           | 学习率              | 通常设为 0.01\\~0.1                  |\n",
    "| `num_class`               | 多分类类别数（多分类任务）| `3`      |\n",
    "| `lambda_l1` / `lambda_l2` | L1/L2 正则项        | 抑制过拟合                           |\n",
    "| `verbosity`               | 日志输出级别           | -1（不输出）或 0、1                  \n",
    "|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c018f3e-f6d2-4379-aa02-64764e085c40",
   "metadata": {},
   "source": [
    "### 📌 2. 树结构参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2741295b-d3e0-4e8e-b8ca-544561c71888",
   "metadata": {},
   "source": [
    "| 参数                 | 作用                 | 示例                              |\n",
    "| ------------------ | ------------------ |----------------- |\n",
    "| `num_leaves`       | 单棵树的最大叶子数（影响模型复杂度） |越大模型越复杂（默认 31）     |\n",
    "| `max_depth`        | 树的最大深度             |  控制过拟合                        |\n",
    "| `min_data_in_leaf` | 每个叶子最小数据量          |防止过拟合                           |\n",
    "| `feature_fraction` | 特征子采样比例（防止过拟合）     |防止过拟合，提高训练速度          |\n",
    "| `bagging_fraction` | 数据子采样比例            | 一般配合 bagging\\_freq 使用           |\n",
    "| `bagging_freq`     | 子采样频率（每 k 次迭代抽样一次） |              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e793a3-f49a-45c5-997e-66f82fbd99c6",
   "metadata": {},
   "source": [
    "## 五、优缺点总结\n",
    "#### ✅ 优点：\n",
    "支持大规模数据训练，比 XGBoost 更快更节省内存；\n",
    "\n",
    "支持原生类别特征；\n",
    "\n",
    "收敛速度快；\n",
    "\n",
    "可用于分布式训练；\n",
    "\n",
    "灵活性强，支持回归、分类、排序等多种任务；\n",
    "\n",
    "支持 GPU 加速。\n",
    "\n",
    "#### ❌ 缺点：\n",
    "leaf-wise 策略容易过拟合，需要调参控制；\n",
    "\n",
    "构造复杂的模型，可能对小数据集表现过拟合；\n",
    "\n",
    "对于数据预处理要求较高（如不能有 NaN，需要提前处理）；\n",
    "\n",
    "超参数较多，调参成本较高。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d75380-1198-4648-b479-23accd4de0f9",
   "metadata": {},
   "source": [
    "## 六、简单使用示例代码（分类任务）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91729c-c848-4b47-b74e-12f49806463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载数据\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 创建数据集\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# 设置参数\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# 训练模型\n",
    "model = lgb.train(params, train_data, num_boost_round=100, valid_sets=[test_data], early_stopping_rounds=10)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = [1 if prob > 0.5 else 0 for prob in y_pred]\n",
    "\n",
    "# 评估\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721356d1-de22-4519-8f01-1358b8345948",
   "metadata": {},
   "source": [
    "## 七、适用场景\n",
    "大数据建模：百万级别数据训练；\n",
    "\n",
    "排名任务（如推荐系统）；\n",
    "\n",
    "高频交易、CTR预估等对效率要求极高的任务；\n",
    "\n",
    "工业级部署、线上推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a7c58-3ac6-465b-b535-ce4b196b8d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9ec7c2c-274d-402e-8dbc-583ae7486171",
   "metadata": {},
   "source": [
    "# 🧭 LightGBM 常用方法概览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a0d6ca-1289-49b5-9b13-2c851da5228a",
   "metadata": {},
   "source": [
    "## 🔹 一、两种接口方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746445c-f2a2-42a9-aff0-be24d78d0742",
   "metadata": {},
   "source": [
    "| 接口方式         | 类别                                | 说明                  |\n",
    "| ------------ | --------------------------------- | ------------------- |\n",
    "| 原生接口         | `lgb.train()`                     | 功能强大，支持细粒度控制        |\n",
    "| sklearn 风格接口 | `LGBMClassifier`, `LGBMRegressor` | 使用方式类似 sklearn，更易集成 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9524421-3947-4b97-85e9-954311020406",
   "metadata": {},
   "source": [
    "## 🔹 二、原生接口：lgb.train() 常用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ac40e-bfcb-4eb1-b079-a5df29c9f7db",
   "metadata": {},
   "source": [
    "### 1. lgb.Dataset()\n",
    "创建训练数据集对象，可设置类别特征：\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=['性别'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cb10c-817a-4cfb-8b7d-32baf46ac71a",
   "metadata": {},
   "source": [
    "### 2. 🔹 lgb.train(params, train_data, ...)  🔹\n",
    "🔹核心训练函数🔹：\n",
    "\n",
    "model = lgb.train(params, train_data, num_boost_round=100, valid_sets=[val_data])\n",
    "\n",
    "数说明：\n",
    "\n",
    "params：模型超参数字典\n",
    "\n",
    "num_boost_round：迭代次数\n",
    "\n",
    "valid_sets：验证集列表\n",
    "\n",
    "early_stopping_rounds：早停轮数（推荐使用）\n",
    "\n",
    "### 3. model.predict(X)\n",
    "预测方法：\n",
    "\n",
    "y_pred = model.predict(X, num_iteration=None, raw_score=False)  --->  输出预测类别或数值\n",
    "\n",
    "model.predict_proba(X)  --->  输出每个类别的概率（仅分类任务）\n",
    "\n",
    "model.predict_leaf(X)  --->  返回每棵树的叶子索引\n",
    "\n",
    "model.predict_raw(X)  --->  返回原始分数（未转换为概率或标签）\n",
    "\n",
    "\n",
    "### 4. 模型分析与调试\n",
    "model.score(X, y)   --->  返回默认指标（分类为准确率，回归为 R²）\n",
    "\n",
    "model.feature_importances_   --->  特征重要性（数组）\n",
    "\n",
    "model.booster_  --->  返回底层 Booster 对象（访问底层原生方法）\n",
    "\n",
    "### 5. model.save_model('model.txt')\n",
    "保存模型：\n",
    "\n",
    "model.save_model('lightgbm_model.txt')\n",
    "\n",
    "### 6. lgb.Booster(model_file='model.txt')\n",
    "加载模型：\n",
    "\n",
    "model = lgb.Booster(model_file='lightgbm_model.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d76010-60cc-4bf2-be1e-a15aafc1ccdf",
   "metadata": {},
   "source": [
    "# LightGBM 原生 API 方法（lgb.train、Booster 对象）\n",
    "适用于更复杂、灵活的训练过程，比如自定义数据加载、评估函数等。\n",
    "\n",
    "## 1. 训练模型\n",
    "\n",
    "lgb.train(params, train_set, num_boost_round=100, valid_sets=None, early_stopping_rounds=None, ...)\n",
    "\n",
    "params：字典类型，如 'objective': 'binary', 'metric': 'auc'\n",
    "\n",
    "train_set：使用 lgb.Dataset(X, y) 创建\n",
    "\n",
    "valid_sets：验证集列表\n",
    "\n",
    "early_stopping_rounds：启用早停"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36a679-cfd0-4161-baf0-564ad43ab841",
   "metadata": {},
   "source": [
    "## 数据集 lgb.Dataset 常用方法\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    ".construct()：构建内部表示（一般不需要手动调用）\n",
    "\n",
    ".get_data()：获取原始数据\n",
    "\n",
    ".get_label()：获取标签\n",
    "\n",
    ".save_binary(fname)：保存为二进制格式\n",
    "\n",
    ".set_feature_name()：手动指定特征名\n",
    "\n",
    ".set_categorical_feature()：指定类别特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68f89f-6a52-42ac-93be-803141268ff7",
   "metadata": {},
   "source": [
    "## Booster 对象的常用方法\n",
    "训练后返回的是一个 Booster 对象，常用方法如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b819b6-20f0-444b-b583-3f230c4a5b34",
   "metadata": {},
   "source": [
    "| 方法                                                                                         | 功能                |\n",
    "| ------------------------------------------------------------------------------------------ | ----------------- |\n",
    "| `.predict(data, num_iteration=None, raw_score=False, pred_leaf=False, pred_contrib=False)` | 做预测               |\n",
    "| `.save_model(filename)`                                                                    | 保存模型              |\n",
    "| `.load_model(filename)`                                                                    | 加载模型              |\n",
    "| `.feature_importance(importance_type='split')`                                             | 获取特征重要性           |\n",
    "| `.dump_model()`                                                                            | 以 dict 形式输出完整模型结构 |\n",
    "| `.num_trees()`                                                                             | 获取模型树的数量          |\n",
    "| `.num_features()`                                                                          | 获取特征数量            |\n",
    "| `.eval(data, name='eval')`                                                                 | 使用自定义数据进行评估       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43869d0c-2e14-406a-b4ea-a62b57e61401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d038934d-4a22-4a14-b64d-7c6eea3407e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "907aebe1-415d-46e6-b0c4-cc371b089657",
   "metadata": {},
   "source": [
    "# ✅ LGBMClassifier 参数详解表（按功能分类）\n",
    "| 参数名                    | 类型                | 默认值      | 含义           | 备注                                      |\n",
    "| ---------------------- | ----------------- | -------- | ------------ | --------------------------------------- |\n",
    "| **基础控制参数**             |                   |          |              |                                         |\n",
    "| `boosting_type`        | str               | 'gbdt'   | 提升类型（提升算法）   | 可选：`'gbdt'`, `'dart'`, `'goss'`, `'rf'` |\n",
    "| `num_leaves`           | int               | 31       | 单棵树的最大叶子节点数  | 控制模型复杂度，越大越容易过拟合                        |\n",
    "| `max_depth`            | int               | -1       | 树的最大深度       | -1 表示不限制深度                              |\n",
    "| `learning_rate`        | float             | 0.1      | 学习率          | 降低可以提升泛化能力，但训练更慢                        |\n",
    "| `n_estimators`         | int               | 100      | 弱学习器（树）的数量   | 通常需调参选择                                 |\n",
    "| `objective`            | str               | 'binary' | 目标函数         | 分类任务常用：`'binary'`, `'multiclass'`       |\n",
    "| `random_state`         | int               | None     | 随机种子         | 确保结果可复现                                 |\n",
    "| **数据处理参数**             |                   |          |              |                                         |\n",
    "| `class_weight`         | dict / 'balanced' | None     | 样本类别权重       | 适用于样本不平衡（如欺诈检测）                         |\n",
    "| `min_child_samples`    | int               | 20       | 每个叶子节点的最小样本数 | 过小容易过拟合                                 |\n",
    "| `min_child_weight`     | float             | 1e-3     | 子节点的最小权重和    | 防止样本权重过低的节点分裂                           |\n",
    "| `subsample`            | float             | 1.0      | 训练样本采样比例（行）  | 防止过拟合，通常设为 0.7\\~0.9                     |\n",
    "| `colsample_bytree`     | float             | 1.0      | 构建每棵树时列的采样比例 | 通常设为 0.7\\~0.9                           |\n",
    "| `reg_alpha`            | float             | 0.0      | L1正则化系数      | 控制模型复杂度（特征选择）                           |\n",
    "| `reg_lambda`           | float             | 0.0      | L2正则化系数      | 控制模型复杂度（权重缩小）                           |\n",
    "| **多类别任务相关参数**          |                   |          |              |                                         |\n",
    "| `num_class`            | int               | None     | 类别数量         | 多分类任务时必填                                |\n",
    "| **提升方式参数（dart, goss）** |                   |          |              |                                         |\n",
    "| `drop_rate`            | float             | 0.1      | DART 模式下的丢弃率 | 仅在 boosting\\_type='dart' 时使用            |\n",
    "| `top_rate`             | float             | 0.2      | GOSS 的前面比例   | 仅在 boosting\\_type='goss' 时使用            |\n",
    "| `other_rate`           | float             | 0.1      | GOSS 的其他比例   | 仅在 boosting\\_type='goss' 时使用            |\n",
    "| **模型训练控制**             |                   |          |              |                                         |\n",
    "| `n_jobs`               | int               | -1       | 并行线程数        | -1 表示使用全部核心                             |\n",
    "| `verbose`              | int               | 1        | 控制日志输出       | 0（静默），1（默认），2（详细）                       |\n",
    "\n",
    "### 🧭⚠ 注意：learning_rate 和 n_estimators 是强相关的——如果 learning_rate 提高，n_estimators 应该减少，否则容易过拟合。\n",
    "\n",
    "## 📊 、调参指南\n",
    "\n",
    "| 目的            | 推荐参数调整                                                |\n",
    "| ------------- | ----------------------------------------------------- |\n",
    "| 防止过拟合         | 减小 `num_leaves`、增加 `min_child_samples`、降低 `max_depth` |\n",
    "| 提高准确率         | 提高 `num_leaves`，减小 `learning_rate`，增加 `n_estimators`  |\n",
    "| 提高召回率（检测更多欺诈） | 增大 `scale_pos_weight` 或使用 `class_weight='balanced'`   |\n",
    "| 加快训练速度        | 减少 `n_estimators` 或使用较高 `learning_rate`（初期）           |\n",
    "| 特征选择可解释性      | 使用 `model.feature_importances_` 或 SHAP 可视化            |\n",
    "\n",
    "# LightGBM 高级调参技巧\n",
    "## 1. 理解核心参数\n",
    "| 参数                 | 作用        | 说明                          |\n",
    "| ------------------ | --------- | --------------------------- |\n",
    "| `num_leaves`       | 叶子节点数     | 控制模型复杂度，过大容易过拟合             |\n",
    "| `max_depth`        | 树最大深度     | 限制树深度，防止过拟合                 |\n",
    "| `learning_rate`    | 学习率       | 小学习率 + 多迭代通常效果更好            |\n",
    "| `min_data_in_leaf` | 叶子节点最小样本数 | 防止叶子过拟合，调大更稳定               |\n",
    "| `feature_fraction` | 特征子采样比例   | 减少过拟合，增加随机性                 |\n",
    "| `bagging_fraction` | 数据采样比例    | 减少过拟合，和 `bagging_freq` 配合使用 |\n",
    "| `bagging_freq`     | 数据采样频率    | 非零时启用bagging                |\n",
    "| `lambda_l1`        | L1 正则化系数  | 增加模型稀疏性，控制过拟合               |\n",
    "| `lambda_l2`        | L2 正则化系数  | 防止过拟合                       |\n",
    "\n",
    "## 2. 调参流程建议\n",
    "### 2.1 学习率与迭代次数\n",
    "先固定 num_leaves、max_depth 等复杂度参数，用较大学习率（如 0.1）跑出初步结果，找到大致需要的迭代次数。\n",
    "\n",
    "降低学习率（如 0.01~0.05）并增加迭代次数（>1000），提升模型精度。\n",
    "\n",
    "### 2.2 调整树的复杂度\n",
    "调整 num_leaves，注意一般建议不超过 2^(max_depth)，否则会出现过拟合。\n",
    "\n",
    "通过限制 max_depth 控制树的深度，防止生成过深树。\n",
    "\n",
    "通过 min_data_in_leaf 控制叶子节点上的最小样本数，避免过拟合。\n",
    "\n",
    "### 2.3 使用正则化\n",
    "加大 lambda_l1 和 lambda_l2 可以减少过拟合。\n",
    "\n",
    "对于稀疏数据，L1 正则化更有效。\n",
    "\n",
    "### 2.4 采样与随机性\n",
    "使用 feature_fraction 随机采样特征，减少模型过拟合。\n",
    "\n",
    "使用 bagging_fraction 和 bagging_freq 进行行采样，增加模型鲁棒性。\n",
    "\n",
    "## 3. 进阶参数调节\n",
    "| 参数                 | 建议范围     | 说明                  |\n",
    "| ------------------ | -------- | ------------------- |\n",
    "| `num_leaves`       | 31\\~512  | 控制树叶子数量，越大拟合越强，易过拟合 |\n",
    "| `max_depth`        | 5\\~15    | 树深度限制               |\n",
    "| `min_data_in_leaf` | 20\\~1000 | 叶子最小样本数             |\n",
    "| `feature_fraction` | 0.6\\~1.0 | 随机采样特征比例            |\n",
    "| `bagging_fraction` | 0.6\\~1.0 | 随机采样数据比例            |\n",
    "| `bagging_freq`     | 1\\~10    | 采样频率                |\n",
    "| `lambda_l1`        | 0\\~5     | L1 正则化强度            |\n",
    "| `lambda_l2`        | 0\\~5     | L2 正则化强度            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd40f5-904b-4046-aa5a-d1c0a9835bf8",
   "metadata": {},
   "source": [
    "## 4. 调参示例（Python）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fe8bf-bceb-48f3-8362-bde52cc506f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 准备数据\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,\n",
    "    'max_depth': 10,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.2,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "model = lgb.train(params, train_data, valid_sets=[val_data], \n",
    "                  num_boost_round=2000, early_stopping_rounds=100)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print('AUC:', roc_auc_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a9fa17-22cd-4c6f-b613-29029904f460",
   "metadata": {},
   "source": [
    "## 5. 其他高级技巧\n",
    "类别特征处理：确保类别特征设置为 category 类型，LightGBM 可直接原生支持。\n",
    "\n",
    "使用 GPU 加速：设置 device = 'gpu'，显著缩短训练时间。\n",
    "\n",
    "交叉验证：使用 lgb.cv() 进行K折交叉验证，获取更稳定参数。\n",
    "\n",
    "调参自动化：结合 Optuna、Hyperopt 等自动调参库，提高效率。\n",
    "\n",
    "早停策略：合理设置 early_stopping_rounds，防止过拟合。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be6179-8844-485c-b0f0-925f3a149132",
   "metadata": {},
   "source": [
    "### ✅小结\n",
    "| 场景          | 推荐参数                                           |\n",
    "| ----------- | ---------------------------------------------- |\n",
    "| 欺诈检测（极度不平衡） | `class_weight='balanced'` 或 `scale_pos_weight` |\n",
    "| 想让模型更复杂     | 提高 `num_leaves`, 降低 `min_child_samples`        |\n",
    "| 想提高训练速度     | 提高 `learning_rate`, 减少 `n_estimators`          |\n",
    "| 想避免过拟合      | 降低 `max_depth`, 增加 `reg_alpha`, `reg_lambda`   |\n",
    "\n",
    "## 6. 总结\n",
    "| 调参重点       | 说明                 |\n",
    "| ---------- | ------------------ |\n",
    "| 学习率 & 迭代次数 | 低学习率 + 多迭代带来更好泛化效果 |\n",
    "| 叶子数 & 深度   | 控制模型复杂度，防止过拟合      |\n",
    "| 正则化参数      | L1、L2 正则化减轻过拟合     |\n",
    "| 特征与数据采样    | 提升模型鲁棒性和泛化能力       |\n",
    "| 早停 & 交叉验证  | 避免过拟合并获取稳定参数       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141a31d-b864-4cbe-9587-8935fbf98622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
